{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deng_Yinglu_Lab 4.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "GTO2KMti07__",
        "YAnuY8Sv1DoO",
        "1foS74O01FfP"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xxMXNDF7ckw"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "# DMA Fall 21\n",
        "\n",
        "**Note** : This entire lab will be manually evaluated.\n",
        "\n",
        "Name : 'Yinglu Deng'\n",
        "\n",
        "Collaborator : ''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oyb_RNpFreOr"
      },
      "source": [
        "# Lab 4: Neural Networks #\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yj9Uh79ereOs"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV, ParameterGrid\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6SRFrhfreOt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "801c1aaa-8089-4b89-9be5-e804771c16c5"
      },
      "source": [
        "!wget http://askoski.berkeley.edu/~zp/lab_4_training.csv\n",
        "!wget http://askoski.berkeley.edu/~zp/lab_4_test.csv\n",
        "\n",
        "df_train = pd.read_csv('./lab_4_training.csv')\n",
        "df_test = pd.read_csv('./lab_4_test.csv')\n",
        "df_train.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-22 04:54:33--  http://askoski.berkeley.edu/~zp/lab_4_training.csv\n",
            "Resolving askoski.berkeley.edu (askoski.berkeley.edu)... 169.229.192.179\n",
            "Connecting to askoski.berkeley.edu (askoski.berkeley.edu)|169.229.192.179|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 79177 (77K) [text/csv]\n",
            "Saving to: ‘lab_4_training.csv’\n",
            "\n",
            "lab_4_training.csv  100%[===================>]  77.32K  57.7KB/s    in 1.3s    \n",
            "\n",
            "2021-09-22 04:54:37 (57.7 KB/s) - ‘lab_4_training.csv’ saved [79177/79177]\n",
            "\n",
            "--2021-09-22 04:54:37--  http://askoski.berkeley.edu/~zp/lab_4_test.csv\n",
            "Resolving askoski.berkeley.edu (askoski.berkeley.edu)... 169.229.192.179\n",
            "Connecting to askoski.berkeley.edu (askoski.berkeley.edu)|169.229.192.179|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 26519 (26K) [text/csv]\n",
            "Saving to: ‘lab_4_test.csv’\n",
            "\n",
            "lab_4_test.csv      100%[===================>]  25.90K  34.8KB/s    in 0.7s    \n",
            "\n",
            "2021-09-22 04:54:38 (34.8 KB/s) - ‘lab_4_test.csv’ saved [26519/26519]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>year</th>\n",
              "      <th>eyecolor</th>\n",
              "      <th>height</th>\n",
              "      <th>miles</th>\n",
              "      <th>brothers</th>\n",
              "      <th>sisters</th>\n",
              "      <th>computertime</th>\n",
              "      <th>exercise</th>\n",
              "      <th>exercisehours</th>\n",
              "      <th>musiccds</th>\n",
              "      <th>playgames</th>\n",
              "      <th>watchtv</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>577</td>\n",
              "      <td>male</td>\n",
              "      <td>20</td>\n",
              "      <td>third</td>\n",
              "      <td>hazel</td>\n",
              "      <td>72.0</td>\n",
              "      <td>180.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>677</td>\n",
              "      <td>male</td>\n",
              "      <td>19</td>\n",
              "      <td>second</td>\n",
              "      <td>hazel</td>\n",
              "      <td>72.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>16.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>9.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1738</td>\n",
              "      <td>male</td>\n",
              "      <td>20</td>\n",
              "      <td>second</td>\n",
              "      <td>brown</td>\n",
              "      <td>63.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>15.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>4.5</td>\n",
              "      <td>15.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>13.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1355</td>\n",
              "      <td>male</td>\n",
              "      <td>20</td>\n",
              "      <td>third</td>\n",
              "      <td>green</td>\n",
              "      <td>78.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>9.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>891</td>\n",
              "      <td>female</td>\n",
              "      <td>19</td>\n",
              "      <td>second</td>\n",
              "      <td>green</td>\n",
              "      <td>67.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>2.0</td>\n",
              "      <td>164.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  gender  age    year  ... exercisehours  musiccds  playgames  watchtv\n",
              "0         577    male   20   third  ...           0.0     100.0       10.0     10.0\n",
              "1         677    male   19  second  ...           9.0      70.0        3.0      5.0\n",
              "2        1738    male   20  second  ...           4.5      15.0        4.0     13.0\n",
              "3        1355    male   20   third  ...           9.0      20.0       10.0     10.0\n",
              "4         891  female   19  second  ...           2.0     164.0        0.0      2.0\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGt_10ZAreOv"
      },
      "source": [
        "***\n",
        "### Question 1###\n",
        "Calculate a baseline accuracy measure using the majority class, assuming a target variable of 'gender'. The majority class is the most common value of the target variable in a particular dataset. Accuracy is calculated as (true positives + true negatives) / (all negatives and positives)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZPiLgekreOw"
      },
      "source": [
        "**Question 1.a**  \n",
        "Find the majority class in the training set. If you always predicted this class in the training set, what would your accuracy be?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYjEFc1greOx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e6fc5fb-2721-43ab-a375-d813a04a5e73"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "train_group = df_train.groupby('gender').size()\n",
        "train_group"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "gender\n",
              "female    647\n",
              "male      545\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlDyzPREAX6u",
        "outputId": "54cd65c7-a4e9-4a0c-d88c-c1341c915767"
      },
      "source": [
        "label_list = list(train_group)\n",
        "majority_train_accuracy = max(label_list) / np.sum(label_list)\n",
        "majority_train_accuracy"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5427852348993288"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtvFM-hM0y2o"
      },
      "source": [
        "###ANSWER: The majority class is female. And the accuracy will be 0.5427852348993288."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULPKW0IvreOy"
      },
      "source": [
        "**Question 1.b**   \n",
        "If you always predicted this same class (majority from the training set) in the test set, what would your accuracy be?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfU5mwh405vq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1c0d218-121c-4b7a-f8d1-934a1a620f0e"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "test_group = df_test.groupby('gender').size()\n",
        "test_group"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "gender\n",
              "female    208\n",
              "male      190\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaWk0pM1DCiH",
        "outputId": "547b9db4-b320-4b9e-a6ca-08ff4ceef953"
      },
      "source": [
        "label_list = list(test_group)\n",
        "majority_test_accuracy = max(label_list) / np.sum(label_list)\n",
        "majority_test_accuracy"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5226130653266332"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pINRUJxG05v4"
      },
      "source": [
        "###ANSWER: The majority class is female. And the accuracy will be 0.5226130653266332."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKb2Ju-GreO0"
      },
      "source": [
        "***\n",
        "### Question 2 ###\n",
        "Get started with Neural Networks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYI6e3F3reO0"
      },
      "source": [
        "   \n",
        "Choose a NN implementation (eg: scikit-learn) and specify which you choose. Be sure the implementation allows you to modify the number of hidden layers and hidden nodes per layer.  \n",
        "\n",
        "NOTE: When possible, specify the logsig (sigmoid/logistc) function as the transfer function (another word for activation function) and use Levenberg-Marquardt backpropagation (lbfgs). It is possible to specify logistic in Sklearn MLPclassifier (Neural net).  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4am3sGc4reO1"
      },
      "source": [
        "**Question 2.a**   \n",
        "Train a neural network with a single 10 node hidden layer. Only use the Height feature of the dataset to predict the Gender. You will have to change Gender to a 0 and 1 class. After training, use your trained model to predict the class using the height feature from the training set. What was the accuracy of this prediction?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbAzltaw067l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7731e8b-6f47-44e9-b65f-cd8cf74d2607"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "# use keras as a NN implementation\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn import preprocessing\n",
        "\n",
        "# use the height feature and transform the gender to binary\n",
        "X_train = np.array(df_train[['height']])\n",
        "df_train['gender_binary'] = df_train['gender'].apply(lambda x: 1 if x == 'female' else 0)\n",
        "Y_train = np.array(df_train[['gender_binary']])\n",
        "\n",
        "clf = MLPClassifier(hidden_layer_sizes=(10), activation = 'logistic',\n",
        "                     solver='lbfgs', random_state=1)  #sgd = Stochastic Gradient descent. Also, check 'lbfgs’, ‘adam’}\n",
        "                                                                #Default activation is 'relu'\n",
        "                                                                #Default n_iter_no_change=10\n",
        "\n",
        "clf.fit(X_train,Y_train)\n",
        "\n",
        "print('Accuracy on training---')\n",
        "y_pred_train=clf.predict(X_train)\n",
        "print(accuracy_score(Y_train,y_pred_train))\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on training---\n",
            "0.802013422818792\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuaCk0l0067q"
      },
      "source": [
        "###ANSWER: The accuracy of this prediction for training set is 0.802013422818792."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkqzIeshreO2"
      },
      "source": [
        "**Question 2.b**  \n",
        "Take the trained model from question 2.a and use it to predict the test set. This can be accomplished by taking the trained model and giving it the Height feature values from the test set. What is the accuracy of this model on the test set?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tw25ezWp07hj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84723558-35d0-484b-a058-e1cea4005056"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "X_test = np.array(df_test[['height']])\n",
        "df_test['gender_binary'] = df_test['gender'].apply(lambda x: 1 if x == 'female' else 0)\n",
        "Y_test = np.array(df_test[['gender_binary']])\n",
        "\n",
        "print('Accuracy on test---')\n",
        "y_pred_test=clf.predict(X_test)\n",
        "print(accuracy_score(Y_test,y_pred_test))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test---\n",
            "0.7939698492462312\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbHMAFvw07hm"
      },
      "source": [
        "###ANSWER: The accuracy of this prediction for test set is 0.7939698492462312."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMmIfsNEreO3"
      },
      "source": [
        "**Question 2.c**   \n",
        "Neural Networks tend to prefer smaller, normalized feature values. Try taking the log of the height feature in both training and testing sets or use a Standard Scalar operation in SKlearn to centre and normalize the data between 0-1 for continuous values. Repeat question 2.a and 2.b with the log version or the normalized and centered version of this feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDhCZPaU07_8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dd54857-2795-4adb-ae39-ff46fea10a12"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "from sklearn import preprocessing\n",
        "# use a Standard Scalar operation in SKlearn to centre and normalize the data between 0-1 for continuous values\n",
        "sc=preprocessing.StandardScaler()\n",
        "X_train_scaled=sc.fit_transform(X_train)\n",
        "X_test_scaled=sc.transform(X_test)\n",
        "\n",
        "clf = MLPClassifier(hidden_layer_sizes=(10), activation = 'logistic',\n",
        "                     solver='lbfgs', random_state=1)  #sgd = Stochastic Gradient descent. Also, check 'lbfgs’, ‘adam’}\n",
        "                                                                #Default activation is 'relu'\n",
        "                                                                #Default n_iter_no_change=10\n",
        "\n",
        "clf.fit(X_train_scaled,Y_train)\n",
        "\n",
        "print('Accuracy on training---')\n",
        "y_pred_scaled_train=clf.predict(X_train_scaled)\n",
        "print(accuracy_score(Y_train, y_pred_scaled_train))\n",
        "\n",
        "print('')\n",
        "print('Accuracy on test---')\n",
        "y_pred_scaled_test=clf.predict(X_test_scaled)\n",
        "print(accuracy_score(Y_test, y_pred_scaled_test))\n",
        " "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on training---\n",
            "0.8439597315436241\n",
            "\n",
            "Accuracy on test---\n",
            "0.8542713567839196\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTO2KMti07__"
      },
      "source": [
        "###ANSWER: After normalizing the data, the accuracy of this prediction for training set is 0.8439597315436241 and the accuracy of this prediction for test set is 0.8542713567839196."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_SlOdcarePC"
      },
      "source": [
        "***\n",
        "\n",
        "### Question 3###\n",
        "The rest of features in this dataset barring a few are categorical. No ML method accepts categorical features, so transform year, eyecolor, exercise into a set of binary features, one feature per unique original feature value, and mark the binary feature as ‘1’ if the feature value matches the original value and ‘0’ otherwise. Using only these binary variable transformed features, train and predict the class of the test set. What was your accuracy using Neural Network with a single 10 node hidden layer? During training, use a maximum number of iterations of 50."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjhzBFNV1Aip",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "444a49af-d4a3-4b0f-88ae-b72558ce7f8c"
      },
      "source": [
        "# only get three features\n",
        "df_train_bin = df_train[['year', 'eyecolor', 'exercise']]\n",
        "df_test_bin = df_test[['year', 'eyecolor', 'exercise']]\n",
        "\n",
        "#get dummy variable and convert to array\n",
        "X_train_dummy = np.array(pd.get_dummies(df_train_bin))\n",
        "y_train = df_train['gender']\n",
        "X_test_dummy = np.array(pd.get_dummies(df_test_bin))\n",
        "y_test = df_test['gender']\n",
        "\n",
        "#label coding for target\n",
        "le = LabelEncoder()\n",
        "le.fit(['female', 'male'])\n",
        "y_train = le.transform(y_train).reshape(-1, 1)\n",
        "y_test = le.transform(y_test).reshape(-1, 1)\n",
        "\n",
        "#keras training model\n",
        "model = Sequential()\n",
        "model.add(Dense(units=10, activation='sigmoid'))\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "model.fit(X_train_dummy, y_train, epochs=50) #iter = 50\n",
        "\n",
        "print('Accuracy on training---')\n",
        "y_pred_scaled_train=model.predict(X_train_dummy)\n",
        "y_pred_scaled_train=(y_pred_scaled_train>.5)*1\n",
        "print(accuracy_score(y_train, y_pred_scaled_train))\n",
        "\n",
        "print('')\n",
        "print('Accuracy on test---')\n",
        "y_pred_scaled_test=model.predict(X_test_dummy)\n",
        "y_pred_scaled_test=(y_pred_scaled_test>.5)*1\n",
        "print(accuracy_score(y_test, y_pred_scaled_test))\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "38/38 [==============================] - 1s 886us/step - loss: 0.7376 - accuracy: 0.4622\n",
            "Epoch 2/50\n",
            "38/38 [==============================] - 0s 774us/step - loss: 0.7121 - accuracy: 0.4866\n",
            "Epoch 3/50\n",
            "38/38 [==============================] - 0s 808us/step - loss: 0.6991 - accuracy: 0.5159\n",
            "Epoch 4/50\n",
            "38/38 [==============================] - 0s 889us/step - loss: 0.6933 - accuracy: 0.5159\n",
            "Epoch 5/50\n",
            "38/38 [==============================] - 0s 808us/step - loss: 0.6905 - accuracy: 0.5369\n",
            "Epoch 6/50\n",
            "38/38 [==============================] - 0s 813us/step - loss: 0.6893 - accuracy: 0.5386\n",
            "Epoch 7/50\n",
            "38/38 [==============================] - 0s 805us/step - loss: 0.6886 - accuracy: 0.5369\n",
            "Epoch 8/50\n",
            "38/38 [==============================] - 0s 923us/step - loss: 0.6884 - accuracy: 0.5369\n",
            "Epoch 9/50\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.5403\n",
            "Epoch 10/50\n",
            "38/38 [==============================] - 0s 943us/step - loss: 0.6882 - accuracy: 0.5411\n",
            "Epoch 11/50\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.6882 - accuracy: 0.5336\n",
            "Epoch 12/50\n",
            "38/38 [==============================] - 0s 904us/step - loss: 0.6881 - accuracy: 0.5336\n",
            "Epoch 13/50\n",
            "38/38 [==============================] - 0s 825us/step - loss: 0.6880 - accuracy: 0.5378\n",
            "Epoch 14/50\n",
            "38/38 [==============================] - 0s 841us/step - loss: 0.6880 - accuracy: 0.5394\n",
            "Epoch 15/50\n",
            "38/38 [==============================] - 0s 929us/step - loss: 0.6880 - accuracy: 0.5361\n",
            "Epoch 16/50\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.6879 - accuracy: 0.5378\n",
            "Epoch 17/50\n",
            "38/38 [==============================] - 0s 912us/step - loss: 0.6879 - accuracy: 0.5428\n",
            "Epoch 18/50\n",
            "38/38 [==============================] - 0s 817us/step - loss: 0.6878 - accuracy: 0.5327\n",
            "Epoch 19/50\n",
            "38/38 [==============================] - 0s 855us/step - loss: 0.6878 - accuracy: 0.5419\n",
            "Epoch 20/50\n",
            "38/38 [==============================] - 0s 868us/step - loss: 0.6877 - accuracy: 0.5369\n",
            "Epoch 21/50\n",
            "38/38 [==============================] - 0s 896us/step - loss: 0.6876 - accuracy: 0.5445\n",
            "Epoch 22/50\n",
            "38/38 [==============================] - 0s 928us/step - loss: 0.6876 - accuracy: 0.5419\n",
            "Epoch 23/50\n",
            "38/38 [==============================] - 0s 848us/step - loss: 0.6875 - accuracy: 0.5478\n",
            "Epoch 24/50\n",
            "38/38 [==============================] - 0s 819us/step - loss: 0.6875 - accuracy: 0.5445\n",
            "Epoch 25/50\n",
            "38/38 [==============================] - 0s 810us/step - loss: 0.6875 - accuracy: 0.5378\n",
            "Epoch 26/50\n",
            "38/38 [==============================] - 0s 821us/step - loss: 0.6874 - accuracy: 0.5403\n",
            "Epoch 27/50\n",
            "38/38 [==============================] - 0s 846us/step - loss: 0.6874 - accuracy: 0.5470\n",
            "Epoch 28/50\n",
            "38/38 [==============================] - 0s 834us/step - loss: 0.6873 - accuracy: 0.5503\n",
            "Epoch 29/50\n",
            "38/38 [==============================] - 0s 964us/step - loss: 0.6873 - accuracy: 0.5512\n",
            "Epoch 30/50\n",
            "38/38 [==============================] - 0s 773us/step - loss: 0.6872 - accuracy: 0.5461\n",
            "Epoch 31/50\n",
            "38/38 [==============================] - 0s 805us/step - loss: 0.6872 - accuracy: 0.5503\n",
            "Epoch 32/50\n",
            "38/38 [==============================] - 0s 859us/step - loss: 0.6872 - accuracy: 0.5495\n",
            "Epoch 33/50\n",
            "38/38 [==============================] - 0s 874us/step - loss: 0.6871 - accuracy: 0.5512\n",
            "Epoch 34/50\n",
            "38/38 [==============================] - 0s 794us/step - loss: 0.6872 - accuracy: 0.5461\n",
            "Epoch 35/50\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.6870 - accuracy: 0.5520\n",
            "Epoch 36/50\n",
            "38/38 [==============================] - 0s 910us/step - loss: 0.6870 - accuracy: 0.5512\n",
            "Epoch 37/50\n",
            "38/38 [==============================] - 0s 860us/step - loss: 0.6869 - accuracy: 0.5512\n",
            "Epoch 38/50\n",
            "38/38 [==============================] - 0s 803us/step - loss: 0.6869 - accuracy: 0.5503\n",
            "Epoch 39/50\n",
            "38/38 [==============================] - 0s 807us/step - loss: 0.6868 - accuracy: 0.5495\n",
            "Epoch 40/50\n",
            "38/38 [==============================] - 0s 870us/step - loss: 0.6869 - accuracy: 0.5436\n",
            "Epoch 41/50\n",
            "38/38 [==============================] - 0s 871us/step - loss: 0.6868 - accuracy: 0.5445\n",
            "Epoch 42/50\n",
            "38/38 [==============================] - 0s 990us/step - loss: 0.6868 - accuracy: 0.5512\n",
            "Epoch 43/50\n",
            "38/38 [==============================] - 0s 809us/step - loss: 0.6867 - accuracy: 0.5512\n",
            "Epoch 44/50\n",
            "38/38 [==============================] - 0s 919us/step - loss: 0.6867 - accuracy: 0.5512\n",
            "Epoch 45/50\n",
            "38/38 [==============================] - 0s 840us/step - loss: 0.6866 - accuracy: 0.5512\n",
            "Epoch 46/50\n",
            "38/38 [==============================] - 0s 815us/step - loss: 0.6866 - accuracy: 0.5512\n",
            "Epoch 47/50\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.6866 - accuracy: 0.5512\n",
            "Epoch 48/50\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.6865 - accuracy: 0.5537\n",
            "Epoch 49/50\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.6866 - accuracy: 0.5503\n",
            "Epoch 50/50\n",
            "38/38 [==============================] - 0s 868us/step - loss: 0.6865 - accuracy: 0.5520\n",
            "Accuracy on training---\n",
            "0.5511744966442953\n",
            "\n",
            "Accuracy on test---\n",
            "0.5100502512562815\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyQ1EvAY1Ait"
      },
      "source": [
        "###ANSWER: The accuracy of this prediction for training set is 0.5411073825503355 and the accuracy of this prediction for test set is 0.5402010050251256.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSSr9sBlrePG"
      },
      "source": [
        "***\n",
        "### Question 4###\n",
        "Using a NN, report the accuracy on  the test set of a model that trained only on the height and the eye color features of instances in the training set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMNSlOmJrePG"
      },
      "source": [
        "**Question 4.a**  \n",
        "What is the accuracy on the test set using the original height values (no pre-processing) and eye color as a one-hot?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_vN4tyv1Ckq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d9d0b0f-07d4-4e59-97b9-d9da751ac8b4"
      },
      "source": [
        "# get the height feature\n",
        "df_train_height = df_train[['height']]\n",
        "df_test_height = df_test[['height']]\n",
        "\n",
        "#get dummy variable and convert to array\n",
        "X_train_dummy = pd.get_dummies(df_train[['eyecolor']])\n",
        "y_train = df_train['gender']\n",
        "X_test_dummy = pd.get_dummies(df_test[['eyecolor']])\n",
        "y_test = df_test['gender']\n",
        "\n",
        "X_train_q4 = X_train_dummy.join(df_train_height)\n",
        "X_test_q4 = X_test_dummy.join(df_test_height)\n",
        "\n",
        "#label coding for target\n",
        "le = LabelEncoder()\n",
        "le.fit(['female', 'male'])\n",
        "y_train = le.transform(y_train).reshape(-1, 1)\n",
        "y_test = le.transform(y_test).reshape(-1, 1)\n",
        "\n",
        "#keras training model\n",
        "model = Sequential()\n",
        "model.add(Dense(units=10, activation='sigmoid'))\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "model.fit(X_train_q4, y_train, epochs=50) #iter = 50\n",
        "\n",
        "print('Accuracy on training---')\n",
        "y_pred_scaled_train=model.predict(X_train_q4)\n",
        "y_pred_scaled_train=(y_pred_scaled_train>.5)*1\n",
        "print(accuracy_score(y_train, y_pred_scaled_train))\n",
        "\n",
        "print('')\n",
        "print('Accuracy on test---')\n",
        "y_pred_scaled_test=model.predict(X_test_q4)\n",
        "y_pred_scaled_test=(y_pred_scaled_test>.5)*1\n",
        "print(accuracy_score(y_test, y_pred_scaled_test))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "38/38 [==============================] - 0s 980us/step - loss: 0.6956 - accuracy: 0.5428\n",
            "Epoch 2/50\n",
            "38/38 [==============================] - 0s 861us/step - loss: 0.6882 - accuracy: 0.5428\n",
            "Epoch 3/50\n",
            "38/38 [==============================] - 0s 867us/step - loss: 0.6871 - accuracy: 0.5428\n",
            "Epoch 4/50\n",
            "38/38 [==============================] - 0s 884us/step - loss: 0.6868 - accuracy: 0.5428\n",
            "Epoch 5/50\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.5428\n",
            "Epoch 6/50\n",
            "38/38 [==============================] - 0s 915us/step - loss: 0.6870 - accuracy: 0.5428\n",
            "Epoch 7/50\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.5428\n",
            "Epoch 8/50\n",
            "38/38 [==============================] - 0s 892us/step - loss: 0.6870 - accuracy: 0.5428\n",
            "Epoch 9/50\n",
            "38/38 [==============================] - 0s 862us/step - loss: 0.6874 - accuracy: 0.5428\n",
            "Epoch 10/50\n",
            "38/38 [==============================] - 0s 864us/step - loss: 0.6864 - accuracy: 0.5428\n",
            "Epoch 11/50\n",
            "38/38 [==============================] - 0s 936us/step - loss: 0.6872 - accuracy: 0.5428\n",
            "Epoch 12/50\n",
            "38/38 [==============================] - 0s 830us/step - loss: 0.6867 - accuracy: 0.5428\n",
            "Epoch 13/50\n",
            "38/38 [==============================] - 0s 902us/step - loss: 0.6860 - accuracy: 0.5428\n",
            "Epoch 14/50\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.6877 - accuracy: 0.5428\n",
            "Epoch 15/50\n",
            "38/38 [==============================] - 0s 823us/step - loss: 0.6866 - accuracy: 0.5428\n",
            "Epoch 16/50\n",
            "38/38 [==============================] - 0s 887us/step - loss: 0.6878 - accuracy: 0.5428\n",
            "Epoch 17/50\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.5428\n",
            "Epoch 18/50\n",
            "38/38 [==============================] - 0s 842us/step - loss: 0.6866 - accuracy: 0.5428\n",
            "Epoch 19/50\n",
            "38/38 [==============================] - 0s 939us/step - loss: 0.6872 - accuracy: 0.5428\n",
            "Epoch 20/50\n",
            "38/38 [==============================] - 0s 838us/step - loss: 0.6868 - accuracy: 0.5428\n",
            "Epoch 21/50\n",
            "38/38 [==============================] - 0s 948us/step - loss: 0.6878 - accuracy: 0.5428\n",
            "Epoch 22/50\n",
            "38/38 [==============================] - 0s 845us/step - loss: 0.6870 - accuracy: 0.5428\n",
            "Epoch 23/50\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.6877 - accuracy: 0.5428\n",
            "Epoch 24/50\n",
            "38/38 [==============================] - 0s 900us/step - loss: 0.6870 - accuracy: 0.5428\n",
            "Epoch 25/50\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.5428\n",
            "Epoch 26/50\n",
            "38/38 [==============================] - 0s 829us/step - loss: 0.6862 - accuracy: 0.5428\n",
            "Epoch 27/50\n",
            "38/38 [==============================] - 0s 805us/step - loss: 0.6867 - accuracy: 0.5428\n",
            "Epoch 28/50\n",
            "38/38 [==============================] - 0s 808us/step - loss: 0.6865 - accuracy: 0.5428\n",
            "Epoch 29/50\n",
            "38/38 [==============================] - 0s 811us/step - loss: 0.6879 - accuracy: 0.5428\n",
            "Epoch 30/50\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.6868 - accuracy: 0.5428\n",
            "Epoch 31/50\n",
            "38/38 [==============================] - 0s 849us/step - loss: 0.6872 - accuracy: 0.5428\n",
            "Epoch 32/50\n",
            "38/38 [==============================] - 0s 882us/step - loss: 0.6866 - accuracy: 0.5428\n",
            "Epoch 33/50\n",
            "38/38 [==============================] - 0s 895us/step - loss: 0.6868 - accuracy: 0.5428\n",
            "Epoch 34/50\n",
            "38/38 [==============================] - 0s 883us/step - loss: 0.6874 - accuracy: 0.5428\n",
            "Epoch 35/50\n",
            "38/38 [==============================] - 0s 850us/step - loss: 0.6872 - accuracy: 0.5428\n",
            "Epoch 36/50\n",
            "38/38 [==============================] - 0s 957us/step - loss: 0.6866 - accuracy: 0.5428\n",
            "Epoch 37/50\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.6879 - accuracy: 0.5428\n",
            "Epoch 38/50\n",
            "38/38 [==============================] - 0s 960us/step - loss: 0.6882 - accuracy: 0.5428\n",
            "Epoch 39/50\n",
            "38/38 [==============================] - 0s 912us/step - loss: 0.6873 - accuracy: 0.5428\n",
            "Epoch 40/50\n",
            "38/38 [==============================] - 0s 894us/step - loss: 0.6872 - accuracy: 0.5428\n",
            "Epoch 41/50\n",
            "38/38 [==============================] - 0s 950us/step - loss: 0.6867 - accuracy: 0.5428\n",
            "Epoch 42/50\n",
            "38/38 [==============================] - 0s 990us/step - loss: 0.6863 - accuracy: 0.5428\n",
            "Epoch 43/50\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5428\n",
            "Epoch 44/50\n",
            "38/38 [==============================] - 0s 843us/step - loss: 0.6868 - accuracy: 0.5428\n",
            "Epoch 45/50\n",
            "38/38 [==============================] - 0s 877us/step - loss: 0.6861 - accuracy: 0.5428\n",
            "Epoch 46/50\n",
            "38/38 [==============================] - 0s 872us/step - loss: 0.6880 - accuracy: 0.5428\n",
            "Epoch 47/50\n",
            "38/38 [==============================] - 0s 779us/step - loss: 0.6872 - accuracy: 0.5428\n",
            "Epoch 48/50\n",
            "38/38 [==============================] - 0s 856us/step - loss: 0.6873 - accuracy: 0.5428\n",
            "Epoch 49/50\n",
            "38/38 [==============================] - 0s 916us/step - loss: 0.6870 - accuracy: 0.5428\n",
            "Epoch 50/50\n",
            "38/38 [==============================] - 0s 844us/step - loss: 0.6870 - accuracy: 0.5428\n",
            "Accuracy on training---\n",
            "0.5427852348993288\n",
            "\n",
            "Accuracy on test---\n",
            "0.5226130653266332\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaL2o0TW1Cks"
      },
      "source": [
        "###ANSWER: \n",
        "Original height values (no pre-processing) and eye color as a one-hot:\n",
        "\n",
        "The accuracy of this prediction for training set is 0.5427852348993288 and the accuracy of this prediction for test set is 0.5226130653266332."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NC8Ipx9QrePH"
      },
      "source": [
        "**Question 4.b**  \n",
        "What is the accuracy on the test set using the log of height values (applied to both training and testing sets) and eye color as a one-hot?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFvzNv6O1DG3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97f4fca4-2bad-4b09-b0c8-aecb1b9dabb1"
      },
      "source": [
        "# apply log to the height\n",
        "df_train_temp = df_train.copy()\n",
        "df_train_temp['height'] = df_train_temp['height'].apply('log')\n",
        "df_test_temp = df_test.copy()\n",
        "df_test_temp['height'] = df_test_temp['height'].apply('log')\n",
        "\n",
        "df_train_height = df_train_temp[['height']]\n",
        "df_test_height = df_test_temp[['height']]\n",
        "\n",
        "#get dummy variable and convert to array\n",
        "X_train_dummy = pd.get_dummies(df_train[['eyecolor']])\n",
        "y_train = df_train['gender']\n",
        "X_test_dummy = pd.get_dummies(df_test[['eyecolor']])\n",
        "y_test = df_test['gender']\n",
        "\n",
        "X_train_q4b = X_train_dummy.join(df_train_height)\n",
        "X_test_q4b = X_test_dummy.join(df_test_height)\n",
        "\n",
        "#label coding for target\n",
        "le = LabelEncoder()\n",
        "le.fit(['female', 'male'])\n",
        "y_train = le.transform(y_train).reshape(-1, 1)\n",
        "y_test = le.transform(y_test).reshape(-1, 1)\n",
        "\n",
        "#keras training model\n",
        "model = Sequential()\n",
        "model.add(Dense(units=10, activation='sigmoid'))\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "model.fit(X_train_q4b, y_train, epochs=50) #iter = 50\n",
        "\n",
        "print('Accuracy on training---')\n",
        "y_pred_scaled_train=model.predict(X_train_q4b)\n",
        "y_pred_scaled_train=(y_pred_scaled_train>.5)*1\n",
        "print(accuracy_score(y_train, y_pred_scaled_train))\n",
        "\n",
        "print('')\n",
        "print('Accuracy on test---')\n",
        "y_pred_scaled_test=model.predict(X_test_q4b)\n",
        "y_pred_scaled_test=(y_pred_scaled_test>.5)*1\n",
        "print(accuracy_score(y_test, y_pred_scaled_test))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "38/38 [==============================] - 0s 784us/step - loss: 0.7713 - accuracy: 0.5428\n",
            "Epoch 2/50\n",
            "38/38 [==============================] - 0s 849us/step - loss: 0.7218 - accuracy: 0.5428\n",
            "Epoch 3/50\n",
            "38/38 [==============================] - 0s 824us/step - loss: 0.7038 - accuracy: 0.5428\n",
            "Epoch 4/50\n",
            "38/38 [==============================] - 0s 958us/step - loss: 0.6975 - accuracy: 0.5428\n",
            "Epoch 5/50\n",
            "38/38 [==============================] - 0s 890us/step - loss: 0.6949 - accuracy: 0.5428\n",
            "Epoch 6/50\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.5428\n",
            "Epoch 7/50\n",
            "38/38 [==============================] - 0s 855us/step - loss: 0.6938 - accuracy: 0.5428\n",
            "Epoch 8/50\n",
            "38/38 [==============================] - 0s 852us/step - loss: 0.6936 - accuracy: 0.5428\n",
            "Epoch 9/50\n",
            "38/38 [==============================] - 0s 792us/step - loss: 0.6937 - accuracy: 0.5428\n",
            "Epoch 10/50\n",
            "38/38 [==============================] - 0s 839us/step - loss: 0.6936 - accuracy: 0.5428\n",
            "Epoch 11/50\n",
            "38/38 [==============================] - 0s 902us/step - loss: 0.6936 - accuracy: 0.5428\n",
            "Epoch 12/50\n",
            "38/38 [==============================] - 0s 904us/step - loss: 0.6935 - accuracy: 0.5428\n",
            "Epoch 13/50\n",
            "38/38 [==============================] - 0s 815us/step - loss: 0.6934 - accuracy: 0.5428\n",
            "Epoch 14/50\n",
            "38/38 [==============================] - 0s 910us/step - loss: 0.6935 - accuracy: 0.5344\n",
            "Epoch 15/50\n",
            "38/38 [==============================] - 0s 886us/step - loss: 0.6934 - accuracy: 0.5319\n",
            "Epoch 16/50\n",
            "38/38 [==============================] - 0s 910us/step - loss: 0.6934 - accuracy: 0.5428\n",
            "Epoch 17/50\n",
            "38/38 [==============================] - 0s 880us/step - loss: 0.6933 - accuracy: 0.5428\n",
            "Epoch 18/50\n",
            "38/38 [==============================] - 0s 908us/step - loss: 0.6933 - accuracy: 0.5428\n",
            "Epoch 19/50\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5411\n",
            "Epoch 20/50\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5428\n",
            "Epoch 21/50\n",
            "38/38 [==============================] - 0s 900us/step - loss: 0.6931 - accuracy: 0.5428\n",
            "Epoch 22/50\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5428\n",
            "Epoch 23/50\n",
            "38/38 [==============================] - 0s 834us/step - loss: 0.6931 - accuracy: 0.5428\n",
            "Epoch 24/50\n",
            "38/38 [==============================] - 0s 901us/step - loss: 0.6930 - accuracy: 0.5428\n",
            "Epoch 25/50\n",
            "38/38 [==============================] - 0s 826us/step - loss: 0.6931 - accuracy: 0.5428\n",
            "Epoch 26/50\n",
            "38/38 [==============================] - 0s 949us/step - loss: 0.6930 - accuracy: 0.5428\n",
            "Epoch 27/50\n",
            "38/38 [==============================] - 0s 971us/step - loss: 0.6930 - accuracy: 0.5428\n",
            "Epoch 28/50\n",
            "38/38 [==============================] - 0s 877us/step - loss: 0.6930 - accuracy: 0.5428\n",
            "Epoch 29/50\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5428\n",
            "Epoch 30/50\n",
            "38/38 [==============================] - 0s 952us/step - loss: 0.6931 - accuracy: 0.5428\n",
            "Epoch 31/50\n",
            "38/38 [==============================] - 0s 919us/step - loss: 0.6929 - accuracy: 0.5403\n",
            "Epoch 32/50\n",
            "38/38 [==============================] - 0s 810us/step - loss: 0.6928 - accuracy: 0.5428\n",
            "Epoch 33/50\n",
            "38/38 [==============================] - 0s 783us/step - loss: 0.6928 - accuracy: 0.5428\n",
            "Epoch 34/50\n",
            "38/38 [==============================] - 0s 795us/step - loss: 0.6928 - accuracy: 0.5352\n",
            "Epoch 35/50\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5428\n",
            "Epoch 36/50\n",
            "38/38 [==============================] - 0s 983us/step - loss: 0.6927 - accuracy: 0.5428\n",
            "Epoch 37/50\n",
            "38/38 [==============================] - 0s 868us/step - loss: 0.6927 - accuracy: 0.5428\n",
            "Epoch 38/50\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5428\n",
            "Epoch 39/50\n",
            "38/38 [==============================] - 0s 928us/step - loss: 0.6926 - accuracy: 0.5428\n",
            "Epoch 40/50\n",
            "38/38 [==============================] - 0s 981us/step - loss: 0.6926 - accuracy: 0.5419\n",
            "Epoch 41/50\n",
            "38/38 [==============================] - 0s 914us/step - loss: 0.6925 - accuracy: 0.5428\n",
            "Epoch 42/50\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5428\n",
            "Epoch 43/50\n",
            "38/38 [==============================] - 0s 845us/step - loss: 0.6926 - accuracy: 0.5428\n",
            "Epoch 44/50\n",
            "38/38 [==============================] - 0s 922us/step - loss: 0.6924 - accuracy: 0.5428\n",
            "Epoch 45/50\n",
            "38/38 [==============================] - 0s 972us/step - loss: 0.6925 - accuracy: 0.5428\n",
            "Epoch 46/50\n",
            "38/38 [==============================] - 0s 893us/step - loss: 0.6924 - accuracy: 0.5428\n",
            "Epoch 47/50\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5428\n",
            "Epoch 48/50\n",
            "38/38 [==============================] - 0s 959us/step - loss: 0.6924 - accuracy: 0.5428\n",
            "Epoch 49/50\n",
            "38/38 [==============================] - 0s 873us/step - loss: 0.6924 - accuracy: 0.5428\n",
            "Epoch 50/50\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5428\n",
            "Accuracy on training---\n",
            "0.5427852348993288\n",
            "\n",
            "Accuracy on test---\n",
            "0.5226130653266332\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pt3NMp1M1DG4"
      },
      "source": [
        "###ANSWER: \n",
        "The log of height values and eye color as a one-hot: \n",
        "\n",
        "The accuracy of this prediction for training set is 0.5427852348993288 and the accuracy of this prediction for test set is 0.5226130653266332."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYm2jqnprePI"
      },
      "source": [
        "**Question 4.c**  \n",
        "What is the accuracy on the test set using the Z-score of height values and eye color as a one-hot? \n",
        "\n",
        "Z-score is a normalization function. It is the value of a feature minus the average value for that feature (in the training set), divided by the standard deviation of that feature (in the training set). Remember that, whenever applying a function to a feature in the training set, it also has to be applied to that same feature in the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3mDjF6N1DoN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4aebf88e-71e9-41a7-bee0-344f3b454333"
      },
      "source": [
        "# z score function\n",
        "h_mean = df_train['height'].mean()\n",
        "h_std = df_train['height'].std()\n",
        "calculate_Zscore = lambda x: (x - h_mean) / h_std\n",
        "\n",
        "# apply z score to the height\n",
        "df_train_temp = df_train.copy()\n",
        "df_train_temp['height'] = df_train_temp['height'].apply(calculate_Zscore)\n",
        "df_test_temp = df_test.copy()\n",
        "df_test_temp['height'] = df_test_temp['height'].apply(calculate_Zscore)\n",
        "\n",
        "df_train_height = df_train_temp[['height']]\n",
        "df_test_height = df_test_temp[['height']]\n",
        "\n",
        "#get dummy variable and convert to array\n",
        "X_train_dummy = pd.get_dummies(df_train[['eyecolor']])\n",
        "y_train = df_train['gender']\n",
        "X_test_dummy = pd.get_dummies(df_test[['eyecolor']])\n",
        "y_test = df_test['gender']\n",
        "\n",
        "X_train_q4c = X_train_dummy.join(df_train_height)\n",
        "X_test_q4c = X_test_dummy.join(df_test_height)\n",
        "\n",
        "#label coding for target\n",
        "le = LabelEncoder()\n",
        "le.fit(['female', 'male'])\n",
        "y_train = le.transform(y_train).reshape(-1, 1)\n",
        "y_test = le.transform(y_test).reshape(-1, 1)\n",
        "\n",
        "#keras training model\n",
        "model = Sequential()\n",
        "model.add(Dense(units=10, activation='sigmoid'))\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "model.fit(X_train_q4c, y_train, epochs=50) #iter = 50\n",
        "\n",
        "print('Accuracy on training---')\n",
        "y_pred_scaled_train=model.predict(X_train_q4c)\n",
        "y_pred_scaled_train=(y_pred_scaled_train>.5)*1\n",
        "print(accuracy_score(y_train, y_pred_scaled_train))\n",
        "\n",
        "print('')\n",
        "print('Accuracy on test---')\n",
        "y_pred_scaled_test=model.predict(X_test_q4c)\n",
        "y_pred_scaled_test=(y_pred_scaled_test>.5)*1\n",
        "print(accuracy_score(y_test, y_pred_scaled_test))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "38/38 [==============================] - 0s 833us/step - loss: 0.6521 - accuracy: 0.6577\n",
            "Epoch 2/50\n",
            "38/38 [==============================] - 0s 845us/step - loss: 0.6401 - accuracy: 0.7651\n",
            "Epoch 3/50\n",
            "38/38 [==============================] - 0s 992us/step - loss: 0.6311 - accuracy: 0.8104\n",
            "Epoch 4/50\n",
            "38/38 [==============================] - 0s 942us/step - loss: 0.6237 - accuracy: 0.8163\n",
            "Epoch 5/50\n",
            "38/38 [==============================] - 0s 915us/step - loss: 0.6174 - accuracy: 0.8020\n",
            "Epoch 6/50\n",
            "38/38 [==============================] - 0s 829us/step - loss: 0.6117 - accuracy: 0.8037\n",
            "Epoch 7/50\n",
            "38/38 [==============================] - 0s 899us/step - loss: 0.6060 - accuracy: 0.7995\n",
            "Epoch 8/50\n",
            "38/38 [==============================] - 0s 840us/step - loss: 0.6005 - accuracy: 0.7987\n",
            "Epoch 9/50\n",
            "38/38 [==============================] - 0s 958us/step - loss: 0.5951 - accuracy: 0.7911\n",
            "Epoch 10/50\n",
            "38/38 [==============================] - 0s 817us/step - loss: 0.5898 - accuracy: 0.8054\n",
            "Epoch 11/50\n",
            "38/38 [==============================] - 0s 863us/step - loss: 0.5845 - accuracy: 0.8070\n",
            "Epoch 12/50\n",
            "38/38 [==============================] - 0s 831us/step - loss: 0.5793 - accuracy: 0.8096\n",
            "Epoch 13/50\n",
            "38/38 [==============================] - 0s 872us/step - loss: 0.5741 - accuracy: 0.8121\n",
            "Epoch 14/50\n",
            "38/38 [==============================] - 0s 876us/step - loss: 0.5689 - accuracy: 0.8121\n",
            "Epoch 15/50\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.5638 - accuracy: 0.8121\n",
            "Epoch 16/50\n",
            "38/38 [==============================] - 0s 944us/step - loss: 0.5589 - accuracy: 0.8154\n",
            "Epoch 17/50\n",
            "38/38 [==============================] - 0s 890us/step - loss: 0.5538 - accuracy: 0.8196\n",
            "Epoch 18/50\n",
            "38/38 [==============================] - 0s 837us/step - loss: 0.5489 - accuracy: 0.8272\n",
            "Epoch 19/50\n",
            "38/38 [==============================] - 0s 834us/step - loss: 0.5441 - accuracy: 0.8314\n",
            "Epoch 20/50\n",
            "38/38 [==============================] - 0s 871us/step - loss: 0.5393 - accuracy: 0.8372\n",
            "Epoch 21/50\n",
            "38/38 [==============================] - 0s 951us/step - loss: 0.5347 - accuracy: 0.8347\n",
            "Epoch 22/50\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.5300 - accuracy: 0.8356\n",
            "Epoch 23/50\n",
            "38/38 [==============================] - 0s 823us/step - loss: 0.5255 - accuracy: 0.8372\n",
            "Epoch 24/50\n",
            "38/38 [==============================] - 0s 864us/step - loss: 0.5211 - accuracy: 0.8423\n",
            "Epoch 25/50\n",
            "38/38 [==============================] - 0s 813us/step - loss: 0.5167 - accuracy: 0.8414\n",
            "Epoch 26/50\n",
            "38/38 [==============================] - 0s 864us/step - loss: 0.5124 - accuracy: 0.8381\n",
            "Epoch 27/50\n",
            "38/38 [==============================] - 0s 894us/step - loss: 0.5083 - accuracy: 0.8406\n",
            "Epoch 28/50\n",
            "38/38 [==============================] - 0s 816us/step - loss: 0.5042 - accuracy: 0.8431\n",
            "Epoch 29/50\n",
            "38/38 [==============================] - 0s 873us/step - loss: 0.5004 - accuracy: 0.8423\n",
            "Epoch 30/50\n",
            "38/38 [==============================] - 0s 840us/step - loss: 0.4965 - accuracy: 0.8423\n",
            "Epoch 31/50\n",
            "38/38 [==============================] - 0s 827us/step - loss: 0.4927 - accuracy: 0.8431\n",
            "Epoch 32/50\n",
            "38/38 [==============================] - 0s 977us/step - loss: 0.4889 - accuracy: 0.8423\n",
            "Epoch 33/50\n",
            "38/38 [==============================] - 0s 987us/step - loss: 0.4853 - accuracy: 0.8431\n",
            "Epoch 34/50\n",
            "38/38 [==============================] - 0s 917us/step - loss: 0.4817 - accuracy: 0.8431\n",
            "Epoch 35/50\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.4783 - accuracy: 0.8414\n",
            "Epoch 36/50\n",
            "38/38 [==============================] - 0s 870us/step - loss: 0.4750 - accuracy: 0.8389\n",
            "Epoch 37/50\n",
            "38/38 [==============================] - 0s 880us/step - loss: 0.4718 - accuracy: 0.8414\n",
            "Epoch 38/50\n",
            "38/38 [==============================] - 0s 891us/step - loss: 0.4686 - accuracy: 0.8414\n",
            "Epoch 39/50\n",
            "38/38 [==============================] - 0s 821us/step - loss: 0.4655 - accuracy: 0.8414\n",
            "Epoch 40/50\n",
            "38/38 [==============================] - 0s 896us/step - loss: 0.4625 - accuracy: 0.8414\n",
            "Epoch 41/50\n",
            "38/38 [==============================] - 0s 840us/step - loss: 0.4596 - accuracy: 0.8414\n",
            "Epoch 42/50\n",
            "38/38 [==============================] - 0s 887us/step - loss: 0.4568 - accuracy: 0.8414\n",
            "Epoch 43/50\n",
            "38/38 [==============================] - 0s 786us/step - loss: 0.4541 - accuracy: 0.8414\n",
            "Epoch 44/50\n",
            "38/38 [==============================] - 0s 820us/step - loss: 0.4514 - accuracy: 0.8414\n",
            "Epoch 45/50\n",
            "38/38 [==============================] - 0s 876us/step - loss: 0.4489 - accuracy: 0.8414\n",
            "Epoch 46/50\n",
            "38/38 [==============================] - 0s 993us/step - loss: 0.4465 - accuracy: 0.8414\n",
            "Epoch 47/50\n",
            "38/38 [==============================] - 0s 865us/step - loss: 0.4441 - accuracy: 0.8414\n",
            "Epoch 48/50\n",
            "38/38 [==============================] - 0s 862us/step - loss: 0.4418 - accuracy: 0.8414\n",
            "Epoch 49/50\n",
            "38/38 [==============================] - 0s 889us/step - loss: 0.4395 - accuracy: 0.8414\n",
            "Epoch 50/50\n",
            "38/38 [==============================] - 0s 938us/step - loss: 0.4374 - accuracy: 0.8414\n",
            "Accuracy on training---\n",
            "0.8414429530201343\n",
            "\n",
            "Accuracy on test---\n",
            "0.8417085427135679\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAnuY8Sv1DoO"
      },
      "source": [
        "###ANSWER: \n",
        "The Z-score of height values and eye color as a one-hot:\n",
        "\n",
        "The accuracy of this prediction for training set is 0.8053691275167785 and the accuracy of this prediction for test set is 0.7989949748743719."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fh9qwu_9rePJ"
      },
      "source": [
        "***\n",
        "### Question 5 ###\n",
        "Repeat question 4 for exercise hours + eye color"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAgHz_r-1EMR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32f27241-2cbe-4678-c99c-ab3b80274341"
      },
      "source": [
        "#same as 4a: no prepocessing for hour + eyecolor one hot\n",
        "#exercise hour features\n",
        "df_train_hour = df_train[['exercisehours']]\n",
        "df_test_hour = df_test[['exercisehours']]\n",
        "\n",
        "#get dummy variable and convert to array\n",
        "X_train_dummy = pd.get_dummies(df_train[['eyecolor']])\n",
        "y_train = df_train['gender']\n",
        "X_test_dummy = pd.get_dummies(df_test[['eyecolor']])\n",
        "y_test = df_test['gender']\n",
        "\n",
        "X_train_q5 = X_train_dummy.join(df_train_hour)\n",
        "X_test_q5 = X_test_dummy.join(df_test_hour)\n",
        "\n",
        "#label coding for target\n",
        "le = LabelEncoder()\n",
        "le.fit(['female', 'male'])\n",
        "y_train = le.transform(y_train).reshape(-1, 1)\n",
        "y_test = le.transform(y_test).reshape(-1, 1)\n",
        "\n",
        "#keras training model\n",
        "model = Sequential()\n",
        "model.add(Dense(units=10, activation='sigmoid'))\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "model.fit(X_train_q5, y_train, epochs=50) #iter = 50\n",
        "\n",
        "print('Accuracy on training---')\n",
        "y_pred_scaled_train=model.predict(X_train_q5)\n",
        "y_pred_scaled_train=(y_pred_scaled_train>.5)*1\n",
        "print(accuracy_score(y_train, y_pred_scaled_train))\n",
        "\n",
        "print('')\n",
        "print('Accuracy on test---')\n",
        "y_pred_scaled_test=model.predict(X_test_q5)\n",
        "y_pred_scaled_test=(y_pred_scaled_test>.5)*1\n",
        "print(accuracy_score(y_test, y_pred_scaled_test))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "38/38 [==============================] - 0s 835us/step - loss: 0.7702 - accuracy: 0.4690\n",
            "Epoch 2/50\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.7208 - accuracy: 0.5008\n",
            "Epoch 3/50\n",
            "38/38 [==============================] - 0s 910us/step - loss: 0.7005 - accuracy: 0.5159\n",
            "Epoch 4/50\n",
            "38/38 [==============================] - 0s 834us/step - loss: 0.6915 - accuracy: 0.5294\n",
            "Epoch 5/50\n",
            "38/38 [==============================] - 0s 845us/step - loss: 0.6870 - accuracy: 0.5587\n",
            "Epoch 6/50\n",
            "38/38 [==============================] - 0s 826us/step - loss: 0.6851 - accuracy: 0.5680\n",
            "Epoch 7/50\n",
            "38/38 [==============================] - 0s 810us/step - loss: 0.6843 - accuracy: 0.5654\n",
            "Epoch 8/50\n",
            "38/38 [==============================] - 0s 871us/step - loss: 0.6840 - accuracy: 0.5780\n",
            "Epoch 9/50\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.6838 - accuracy: 0.5738\n",
            "Epoch 10/50\n",
            "38/38 [==============================] - 0s 937us/step - loss: 0.6836 - accuracy: 0.5763\n",
            "Epoch 11/50\n",
            "38/38 [==============================] - 0s 910us/step - loss: 0.6835 - accuracy: 0.5763\n",
            "Epoch 12/50\n",
            "38/38 [==============================] - 0s 858us/step - loss: 0.6834 - accuracy: 0.5747\n",
            "Epoch 13/50\n",
            "38/38 [==============================] - 0s 857us/step - loss: 0.6834 - accuracy: 0.5747\n",
            "Epoch 14/50\n",
            "38/38 [==============================] - 0s 842us/step - loss: 0.6832 - accuracy: 0.5763\n",
            "Epoch 15/50\n",
            "38/38 [==============================] - 0s 876us/step - loss: 0.6832 - accuracy: 0.5747\n",
            "Epoch 16/50\n",
            "38/38 [==============================] - 0s 829us/step - loss: 0.6831 - accuracy: 0.5730\n",
            "Epoch 17/50\n",
            "38/38 [==============================] - 0s 970us/step - loss: 0.6830 - accuracy: 0.5755\n",
            "Epoch 18/50\n",
            "38/38 [==============================] - 0s 842us/step - loss: 0.6830 - accuracy: 0.5738\n",
            "Epoch 19/50\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.6830 - accuracy: 0.5730\n",
            "Epoch 20/50\n",
            "38/38 [==============================] - 0s 881us/step - loss: 0.6829 - accuracy: 0.5730\n",
            "Epoch 21/50\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.6829 - accuracy: 0.5721\n",
            "Epoch 22/50\n",
            "38/38 [==============================] - 0s 923us/step - loss: 0.6828 - accuracy: 0.5755\n",
            "Epoch 23/50\n",
            "38/38 [==============================] - 0s 873us/step - loss: 0.6828 - accuracy: 0.5713\n",
            "Epoch 24/50\n",
            "38/38 [==============================] - 0s 858us/step - loss: 0.6827 - accuracy: 0.5671\n",
            "Epoch 25/50\n",
            "38/38 [==============================] - 0s 814us/step - loss: 0.6826 - accuracy: 0.5730\n",
            "Epoch 26/50\n",
            "38/38 [==============================] - 0s 935us/step - loss: 0.6826 - accuracy: 0.5755\n",
            "Epoch 27/50\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.6825 - accuracy: 0.5730\n",
            "Epoch 28/50\n",
            "38/38 [==============================] - 0s 986us/step - loss: 0.6825 - accuracy: 0.5738\n",
            "Epoch 29/50\n",
            "38/38 [==============================] - 0s 859us/step - loss: 0.6825 - accuracy: 0.5663\n",
            "Epoch 30/50\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.6824 - accuracy: 0.5738\n",
            "Epoch 31/50\n",
            "38/38 [==============================] - 0s 853us/step - loss: 0.6824 - accuracy: 0.5721\n",
            "Epoch 32/50\n",
            "38/38 [==============================] - 0s 909us/step - loss: 0.6824 - accuracy: 0.5671\n",
            "Epoch 33/50\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.6823 - accuracy: 0.5696\n",
            "Epoch 34/50\n",
            "38/38 [==============================] - 0s 899us/step - loss: 0.6823 - accuracy: 0.5755\n",
            "Epoch 35/50\n",
            "38/38 [==============================] - 0s 887us/step - loss: 0.6822 - accuracy: 0.5747\n",
            "Epoch 36/50\n",
            "38/38 [==============================] - 0s 914us/step - loss: 0.6822 - accuracy: 0.5730\n",
            "Epoch 37/50\n",
            "38/38 [==============================] - 0s 797us/step - loss: 0.6821 - accuracy: 0.5705\n",
            "Epoch 38/50\n",
            "38/38 [==============================] - 0s 938us/step - loss: 0.6821 - accuracy: 0.5747\n",
            "Epoch 39/50\n",
            "38/38 [==============================] - 0s 869us/step - loss: 0.6822 - accuracy: 0.5738\n",
            "Epoch 40/50\n",
            "38/38 [==============================] - 0s 905us/step - loss: 0.6822 - accuracy: 0.5780\n",
            "Epoch 41/50\n",
            "38/38 [==============================] - 0s 923us/step - loss: 0.6820 - accuracy: 0.5789\n",
            "Epoch 42/50\n",
            "38/38 [==============================] - 0s 829us/step - loss: 0.6819 - accuracy: 0.5780\n",
            "Epoch 43/50\n",
            "38/38 [==============================] - 0s 971us/step - loss: 0.6820 - accuracy: 0.5688\n",
            "Epoch 44/50\n",
            "38/38 [==============================] - 0s 854us/step - loss: 0.6820 - accuracy: 0.5805\n",
            "Epoch 45/50\n",
            "38/38 [==============================] - 0s 851us/step - loss: 0.6819 - accuracy: 0.5780\n",
            "Epoch 46/50\n",
            "38/38 [==============================] - 0s 841us/step - loss: 0.6819 - accuracy: 0.5805\n",
            "Epoch 47/50\n",
            "38/38 [==============================] - 0s 961us/step - loss: 0.6819 - accuracy: 0.5738\n",
            "Epoch 48/50\n",
            "38/38 [==============================] - 0s 904us/step - loss: 0.6819 - accuracy: 0.5688\n",
            "Epoch 49/50\n",
            "38/38 [==============================] - 0s 811us/step - loss: 0.6819 - accuracy: 0.5780\n",
            "Epoch 50/50\n",
            "38/38 [==============================] - 0s 817us/step - loss: 0.6818 - accuracy: 0.5780\n",
            "Accuracy on training---\n",
            "0.5763422818791947\n",
            "\n",
            "Accuracy on test---\n",
            "0.5678391959798995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBHVnaouB3wU"
      },
      "source": [
        "Original exercisehours values (no pre-processing) and eye color as a one-hot:\n",
        "\n",
        "The accuracy of this prediction for training set is 0.5780201342281879 and the accuracy of this prediction for test set is 0.5527638190954773."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "hIkbQhavE7mg",
        "outputId": "9b40ca8b-0c3c-4859-c89b-a2296b99e50f"
      },
      "source": [
        "df_train[df_train['exercisehours']  == 0]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>year</th>\n",
              "      <th>eyecolor</th>\n",
              "      <th>height</th>\n",
              "      <th>miles</th>\n",
              "      <th>brothers</th>\n",
              "      <th>sisters</th>\n",
              "      <th>computertime</th>\n",
              "      <th>exercise</th>\n",
              "      <th>exercisehours</th>\n",
              "      <th>musiccds</th>\n",
              "      <th>playgames</th>\n",
              "      <th>watchtv</th>\n",
              "      <th>gender_binary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>577</td>\n",
              "      <td>male</td>\n",
              "      <td>20</td>\n",
              "      <td>third</td>\n",
              "      <td>hazel</td>\n",
              "      <td>72.0</td>\n",
              "      <td>180.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>878</td>\n",
              "      <td>female</td>\n",
              "      <td>27</td>\n",
              "      <td>third</td>\n",
              "      <td>hazel</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>108.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1689</td>\n",
              "      <td>female</td>\n",
              "      <td>20</td>\n",
              "      <td>third</td>\n",
              "      <td>blue</td>\n",
              "      <td>64.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1857</td>\n",
              "      <td>male</td>\n",
              "      <td>21</td>\n",
              "      <td>third</td>\n",
              "      <td>hazel</td>\n",
              "      <td>72.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>20.0</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>809</td>\n",
              "      <td>female</td>\n",
              "      <td>20</td>\n",
              "      <td>second</td>\n",
              "      <td>brown</td>\n",
              "      <td>62.0</td>\n",
              "      <td>220.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1175</th>\n",
              "      <td>587</td>\n",
              "      <td>male</td>\n",
              "      <td>20</td>\n",
              "      <td>third</td>\n",
              "      <td>blue</td>\n",
              "      <td>72.0</td>\n",
              "      <td>180.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1176</th>\n",
              "      <td>94</td>\n",
              "      <td>female</td>\n",
              "      <td>21</td>\n",
              "      <td>third</td>\n",
              "      <td>brown</td>\n",
              "      <td>63.0</td>\n",
              "      <td>7000.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>10.0</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>300.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1179</th>\n",
              "      <td>1834</td>\n",
              "      <td>female</td>\n",
              "      <td>20</td>\n",
              "      <td>second</td>\n",
              "      <td>green</td>\n",
              "      <td>71.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>25.0</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1182</th>\n",
              "      <td>1953</td>\n",
              "      <td>female</td>\n",
              "      <td>21</td>\n",
              "      <td>third</td>\n",
              "      <td>green</td>\n",
              "      <td>68.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1186</th>\n",
              "      <td>2065</td>\n",
              "      <td>female</td>\n",
              "      <td>18</td>\n",
              "      <td>first</td>\n",
              "      <td>blue</td>\n",
              "      <td>66.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>14.0</td>\n",
              "      <td>No</td>\n",
              "      <td>0.0</td>\n",
              "      <td>239.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>442 rows × 16 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0  gender  age  ... playgames watchtv  gender_binary\n",
              "0            577    male   20  ...      10.0    10.0              0\n",
              "5            878  female   27  ...       1.0     4.0              1\n",
              "6           1689  female   20  ...       0.0    15.0              1\n",
              "8           1857    male   21  ...       1.0     4.0              0\n",
              "12           809  female   20  ...       0.0     3.0              1\n",
              "...          ...     ...  ...  ...       ...     ...            ...\n",
              "1175         587    male   20  ...       2.0     6.0              0\n",
              "1176          94  female   21  ...       0.0     4.0              1\n",
              "1179        1834  female   20  ...       0.0     4.0              1\n",
              "1182        1953  female   21  ...       0.0    10.0              1\n",
              "1186        2065  female   18  ...       2.0    10.0              1\n",
              "\n",
              "[442 rows x 16 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4ZWfA5fGlng",
        "outputId": "57b9464e-2137-4a67-fd9f-7a1cff11bd57"
      },
      "source": [
        "df_train.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1192, 16)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEL_vIk4B2Tq",
        "outputId": "c24a70a2-c6e8-4c2a-91bc-8db4d6de2607"
      },
      "source": [
        "#same as 4b: log + one hot\n",
        "\n",
        "#drop all the 0 value before converting to log base\n",
        "df_train_temp = df_train.copy()\n",
        "df_train_temp = df_train_temp[df_train_temp['exercisehours'] != 0].dropna()\n",
        "df_test_temp = df_test.copy()\n",
        "df_test_temp = df_test_temp[df_test_temp['exercisehours'] != 0].dropna()\n",
        "\n",
        "# apply log to the exercisehours\n",
        "df_train_temp['exercisehours'] = df_train_temp['exercisehours'].apply('log')\n",
        "df_test_temp['exercisehours'] = df_test_temp['exercisehours'].apply('log')\n",
        "\n",
        "df_train_exe = df_train_temp[['exercisehours']]\n",
        "df_test_exe = df_test_temp[['exercisehours']]\n",
        "\n",
        "#get dummy variable and convert to array\n",
        "X_train_dummy = pd.get_dummies(df_train[['eyecolor']])\n",
        "y_train = df_train['gender']\n",
        "X_test_dummy = pd.get_dummies(df_test[['eyecolor']])\n",
        "y_test = df_test['gender']\n",
        "\n",
        "X_train_q5b = X_train_dummy.join(df_train_exe)\n",
        "X_test_q5b = X_test_dummy.join(df_test_exe)\n",
        "\n",
        "#label coding for target\n",
        "le = LabelEncoder()\n",
        "le.fit(['female', 'male'])\n",
        "y_train = le.transform(y_train).reshape(-1, 1)\n",
        "y_test = le.transform(y_test).reshape(-1, 1)\n",
        "\n",
        "#keras training model\n",
        "model = Sequential()\n",
        "model.add(Dense(units=10, activation='sigmoid'))\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "model.fit(X_train_q5b, y_train, epochs=50) #iter = 50\n",
        "\n",
        "print('Accuracy on training---')\n",
        "y_pred_scaled_train=model.predict(X_train_q5b)\n",
        "y_pred_scaled_train=(y_pred_scaled_train>.5)*1\n",
        "print(accuracy_score(y_train, y_pred_scaled_train))\n",
        "\n",
        "print('')\n",
        "print('Accuracy on test---')\n",
        "y_pred_scaled_test=model.predict(X_test_q5b)\n",
        "y_pred_scaled_test=(y_pred_scaled_test>.5)*1\n",
        "print(accuracy_score(y_test, y_pred_scaled_test))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "38/38 [==============================] - 0s 862us/step - loss: nan - accuracy: 0.5428\n",
            "Epoch 2/50\n",
            "38/38 [==============================] - 0s 839us/step - loss: nan - accuracy: 0.5428\n",
            "Epoch 3/50\n",
            "38/38 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.5428\n",
            "Epoch 4/50\n",
            "38/38 [==============================] - 0s 990us/step - loss: nan - accuracy: 0.5428\n",
            "Epoch 5/50\n",
            "38/38 [==============================] - 0s 905us/step - loss: nan - accuracy: 0.5428\n",
            "Epoch 6/50\n",
            "38/38 [==============================] - 0s 905us/step - loss: nan - accuracy: 0.5428\n",
            "Epoch 7/50\n",
            "38/38 [==============================] - 0s 952us/step - loss: nan - accuracy: 0.5428\n",
            "Epoch 8/50\n",
            "38/38 [==============================] - 0s 892us/step - loss: nan - accuracy: 0.5428\n",
            "Epoch 9/50\n",
            "38/38 [==============================] - 0s 872us/step - loss: nan - accuracy: 0.5428\n",
            "Epoch 10/50\n",
            "38/38 [==============================] - 0s 1000us/step - loss: nan - accuracy: 0.5428\n",
            "Epoch 11/50\n",
            "38/38 [==============================] - 0s 930us/step - loss: nan - accuracy: 0.5428\n",
            "Epoch 12/50\n",
            "38/38 [==============================] - 0s 857us/step - loss: nan - accuracy: 0.5428\n",
            "Epoch 13/50\n",
            "38/38 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.5428\n",
            "Epoch 14/50\n",
            "38/38 [==============================] - 0s 947us/step - loss: nan - accuracy: 0.5428\n",
            "Epoch 15/50\n",
            "38/38 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.5428\n",
            "Epoch 16/50\n",
            "38/38 [==============================] - 0s 985us/step - loss: nan - accuracy: 0.5428\n",
            "Epoch 17/50\n",
            "38/38 [==============================] - 0s 789us/step - loss: nan - accuracy: 0.5428\n",
            "Epoch 18/50\n",
            "38/38 [==============================] - 0s 947us/step - loss: nan - accuracy: 0.5428\n",
            "Epoch 19/50\n",
            "38/38 [==============================] - 0s 785us/step - loss: nan - accuracy: 0.5428\n",
            "Epoch 20/50\n",
            "38/38 [==============================] - 0s 852us/step - loss: nan - accuracy: 0.5428\n",
            "Epoch 21/50\n",
            "38/38 [==============================] - 0s 849us/step - loss: nan - accuracy: 0.5428\n",
            "Epoch 22/50\n",
            "38/38 [==============================] - 0s 805us/step - loss: nan - accuracy: 0.5428\n",
            "Epoch 23/50\n",
            "38/38 [==============================] - 0s 977us/step - loss: nan - accuracy: 0.5428\n",
            "Epoch 24/50\n",
            "38/38 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.5428\n",
            "Epoch 25/50\n",
            "38/38 [==============================] - 0s 838us/step - loss: nan - accuracy: 0.5428\n",
            "Epoch 26/50\n",
            "38/38 [==============================] - 0s 879us/step - loss: nan - accuracy: 0.5428\n",
            "Epoch 27/50\n",
            "38/38 [==============================] - 0s 885us/step - loss: nan - accuracy: 0.5428\n",
            "Epoch 28/50\n",
            "38/38 [==============================] - 0s 835us/step - loss: nan - accuracy: 0.5428\n",
            "Epoch 29/50\n",
            "38/38 [==============================] - 0s 963us/step - loss: nan - accuracy: 0.5428\n",
            "Epoch 30/50\n",
            "38/38 [==============================] - 0s 910us/step - loss: nan - accuracy: 0.5428\n",
            "Epoch 31/50\n",
            "38/38 [==============================] - 0s 861us/step - loss: nan - accuracy: 0.5428\n",
            "Epoch 32/50\n",
            "38/38 [==============================] - 0s 855us/step - loss: nan - accuracy: 0.5428\n",
            "Epoch 33/50\n",
            "38/38 [==============================] - 0s 824us/step - loss: nan - accuracy: 0.5428\n",
            "Epoch 34/50\n",
            "38/38 [==============================] - 0s 933us/step - loss: nan - accuracy: 0.5428\n",
            "Epoch 35/50\n",
            "38/38 [==============================] - 0s 948us/step - loss: nan - accuracy: 0.5428\n",
            "Epoch 36/50\n",
            "38/38 [==============================] - 0s 913us/step - loss: nan - accuracy: 0.5428\n",
            "Epoch 37/50\n",
            "38/38 [==============================] - 0s 948us/step - loss: nan - accuracy: 0.5428\n",
            "Epoch 38/50\n",
            "38/38 [==============================] - 0s 926us/step - loss: nan - accuracy: 0.5428\n",
            "Epoch 39/50\n",
            "38/38 [==============================] - 0s 869us/step - loss: nan - accuracy: 0.5428\n",
            "Epoch 40/50\n",
            "38/38 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.5428\n",
            "Epoch 41/50\n",
            "38/38 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.5428\n",
            "Epoch 42/50\n",
            "38/38 [==============================] - 0s 919us/step - loss: nan - accuracy: 0.5428\n",
            "Epoch 43/50\n",
            "38/38 [==============================] - 0s 862us/step - loss: nan - accuracy: 0.5428\n",
            "Epoch 44/50\n",
            "38/38 [==============================] - 0s 914us/step - loss: nan - accuracy: 0.5428\n",
            "Epoch 45/50\n",
            "38/38 [==============================] - 0s 855us/step - loss: nan - accuracy: 0.5428\n",
            "Epoch 46/50\n",
            "38/38 [==============================] - 0s 881us/step - loss: nan - accuracy: 0.5428\n",
            "Epoch 47/50\n",
            "38/38 [==============================] - 0s 970us/step - loss: nan - accuracy: 0.5428\n",
            "Epoch 48/50\n",
            "38/38 [==============================] - 0s 790us/step - loss: nan - accuracy: 0.5428\n",
            "Epoch 49/50\n",
            "38/38 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.5428\n",
            "Epoch 50/50\n",
            "38/38 [==============================] - 0s 877us/step - loss: nan - accuracy: 0.5428\n",
            "Accuracy on training---\n",
            "0.5427852348993288\n",
            "\n",
            "Accuracy on test---\n",
            "0.5226130653266332\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYbXnwM_Kbxk"
      },
      "source": [
        "The log of exercisehours values and eye color as a one-hot:\n",
        "\n",
        "The accuracy of this prediction for training set is 0.5427852348993288 and the accuracy of this prediction for test set is 0.5226130653266332."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qGTnSZxB2pF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c4a1818-b74c-439a-8061-f858a0743f74"
      },
      "source": [
        "#same as 4c: z score + one hot\n",
        "# z score function\n",
        "e_mean = df_train['exercisehours'].mean()\n",
        "e_std = df_train['exercisehours'].std()\n",
        "calculate_Zscore = lambda x: (x - e_mean) / e_std\n",
        "\n",
        "# apply z score to the exercisehours\n",
        "df_train_temp = df_train.copy()\n",
        "df_train_temp['exercisehours'] = df_train_temp['exercisehours'].apply(calculate_Zscore)\n",
        "df_test_temp = df_test.copy()\n",
        "df_test_temp['exercisehours'] = df_test_temp['exercisehours'].apply(calculate_Zscore)\n",
        "\n",
        "df_train_exe = df_train_temp[['exercisehours']]\n",
        "df_test_exe = df_test_temp[['exercisehours']]\n",
        "\n",
        "#get dummy variable and convert to array\n",
        "X_train_dummy = pd.get_dummies(df_train[['eyecolor']])\n",
        "y_train = df_train['gender']\n",
        "X_test_dummy = pd.get_dummies(df_test[['eyecolor']])\n",
        "y_test = df_test['gender']\n",
        "\n",
        "X_train_q5c = X_train_dummy.join(df_train_exe)\n",
        "X_test_q5c = X_test_dummy.join(df_test_exe)\n",
        "\n",
        "#label coding for target\n",
        "le = LabelEncoder()\n",
        "le.fit(['female', 'male'])\n",
        "y_train = le.transform(y_train).reshape(-1, 1)\n",
        "y_test = le.transform(y_test).reshape(-1, 1)\n",
        "\n",
        "#keras training model\n",
        "model = Sequential()\n",
        "model.add(Dense(units=10, activation='sigmoid'))\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "model.fit(X_train_q5c, y_train, epochs=50) #iter = 50\n",
        "\n",
        "print('Accuracy on training---')\n",
        "y_pred_scaled_train=model.predict(X_train_q5c)\n",
        "y_pred_scaled_train=(y_pred_scaled_train>.5)*1\n",
        "print(accuracy_score(y_train, y_pred_scaled_train))\n",
        "\n",
        "print('')\n",
        "print('Accuracy on test---')\n",
        "y_pred_scaled_test=model.predict(X_test_q5c)\n",
        "y_pred_scaled_test=(y_pred_scaled_test>.5)*1\n",
        "print(accuracy_score(y_test, y_pred_scaled_test))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "38/38 [==============================] - 0s 921us/step - loss: 0.7337 - accuracy: 0.4564\n",
            "Epoch 2/50\n",
            "38/38 [==============================] - 0s 929us/step - loss: 0.7167 - accuracy: 0.4547\n",
            "Epoch 3/50\n",
            "38/38 [==============================] - 0s 918us/step - loss: 0.7073 - accuracy: 0.4488\n",
            "Epoch 4/50\n",
            "38/38 [==============================] - 0s 896us/step - loss: 0.7024 - accuracy: 0.4757\n",
            "Epoch 5/50\n",
            "38/38 [==============================] - 0s 878us/step - loss: 0.7000 - accuracy: 0.4849\n",
            "Epoch 6/50\n",
            "38/38 [==============================] - 0s 868us/step - loss: 0.6986 - accuracy: 0.4933\n",
            "Epoch 7/50\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.6977 - accuracy: 0.5042\n",
            "Epoch 8/50\n",
            "38/38 [==============================] - 0s 955us/step - loss: 0.6971 - accuracy: 0.5076\n",
            "Epoch 9/50\n",
            "38/38 [==============================] - 0s 845us/step - loss: 0.6966 - accuracy: 0.5252\n",
            "Epoch 10/50\n",
            "38/38 [==============================] - 0s 885us/step - loss: 0.6962 - accuracy: 0.5252\n",
            "Epoch 11/50\n",
            "38/38 [==============================] - 0s 841us/step - loss: 0.6960 - accuracy: 0.5252\n",
            "Epoch 12/50\n",
            "38/38 [==============================] - 0s 948us/step - loss: 0.6956 - accuracy: 0.5268\n",
            "Epoch 13/50\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.6953 - accuracy: 0.5268\n",
            "Epoch 14/50\n",
            "38/38 [==============================] - 0s 897us/step - loss: 0.6949 - accuracy: 0.5260\n",
            "Epoch 15/50\n",
            "38/38 [==============================] - 0s 916us/step - loss: 0.6946 - accuracy: 0.5243\n",
            "Epoch 16/50\n",
            "38/38 [==============================] - 0s 821us/step - loss: 0.6943 - accuracy: 0.5277\n",
            "Epoch 17/50\n",
            "38/38 [==============================] - 0s 852us/step - loss: 0.6939 - accuracy: 0.5361\n",
            "Epoch 18/50\n",
            "38/38 [==============================] - 0s 827us/step - loss: 0.6937 - accuracy: 0.5386\n",
            "Epoch 19/50\n",
            "38/38 [==============================] - 0s 848us/step - loss: 0.6934 - accuracy: 0.5294\n",
            "Epoch 20/50\n",
            "38/38 [==============================] - 0s 875us/step - loss: 0.6931 - accuracy: 0.5428\n",
            "Epoch 21/50\n",
            "38/38 [==============================] - 0s 905us/step - loss: 0.6929 - accuracy: 0.5310\n",
            "Epoch 22/50\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5428\n",
            "Epoch 23/50\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5428\n",
            "Epoch 24/50\n",
            "38/38 [==============================] - 0s 901us/step - loss: 0.6921 - accuracy: 0.5428\n",
            "Epoch 25/50\n",
            "38/38 [==============================] - 0s 872us/step - loss: 0.6919 - accuracy: 0.5428\n",
            "Epoch 26/50\n",
            "38/38 [==============================] - 0s 883us/step - loss: 0.6916 - accuracy: 0.5428\n",
            "Epoch 27/50\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5428\n",
            "Epoch 28/50\n",
            "38/38 [==============================] - 0s 983us/step - loss: 0.6912 - accuracy: 0.5428\n",
            "Epoch 29/50\n",
            "38/38 [==============================] - 0s 892us/step - loss: 0.6910 - accuracy: 0.5428\n",
            "Epoch 30/50\n",
            "38/38 [==============================] - 0s 909us/step - loss: 0.6908 - accuracy: 0.5428\n",
            "Epoch 31/50\n",
            "38/38 [==============================] - 0s 995us/step - loss: 0.6906 - accuracy: 0.5428\n",
            "Epoch 32/50\n",
            "38/38 [==============================] - 0s 974us/step - loss: 0.6903 - accuracy: 0.5428\n",
            "Epoch 33/50\n",
            "38/38 [==============================] - 0s 842us/step - loss: 0.6901 - accuracy: 0.5428\n",
            "Epoch 34/50\n",
            "38/38 [==============================] - 0s 822us/step - loss: 0.6899 - accuracy: 0.5428\n",
            "Epoch 35/50\n",
            "38/38 [==============================] - 0s 862us/step - loss: 0.6896 - accuracy: 0.5428\n",
            "Epoch 36/50\n",
            "38/38 [==============================] - 0s 941us/step - loss: 0.6895 - accuracy: 0.5428\n",
            "Epoch 37/50\n",
            "38/38 [==============================] - 0s 908us/step - loss: 0.6893 - accuracy: 0.5428\n",
            "Epoch 38/50\n",
            "38/38 [==============================] - 0s 884us/step - loss: 0.6891 - accuracy: 0.5428\n",
            "Epoch 39/50\n",
            "38/38 [==============================] - 0s 932us/step - loss: 0.6889 - accuracy: 0.5428\n",
            "Epoch 40/50\n",
            "38/38 [==============================] - 0s 905us/step - loss: 0.6887 - accuracy: 0.5428\n",
            "Epoch 41/50\n",
            "38/38 [==============================] - 0s 821us/step - loss: 0.6886 - accuracy: 0.5428\n",
            "Epoch 42/50\n",
            "38/38 [==============================] - 0s 802us/step - loss: 0.6884 - accuracy: 0.5428\n",
            "Epoch 43/50\n",
            "38/38 [==============================] - 0s 913us/step - loss: 0.6882 - accuracy: 0.5428\n",
            "Epoch 44/50\n",
            "38/38 [==============================] - 0s 874us/step - loss: 0.6881 - accuracy: 0.5428\n",
            "Epoch 45/50\n",
            "38/38 [==============================] - 0s 878us/step - loss: 0.6879 - accuracy: 0.5428\n",
            "Epoch 46/50\n",
            "38/38 [==============================] - 0s 901us/step - loss: 0.6878 - accuracy: 0.5428\n",
            "Epoch 47/50\n",
            "38/38 [==============================] - 0s 828us/step - loss: 0.6877 - accuracy: 0.5428\n",
            "Epoch 48/50\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.6875 - accuracy: 0.5428\n",
            "Epoch 49/50\n",
            "38/38 [==============================] - 0s 914us/step - loss: 0.6873 - accuracy: 0.5428\n",
            "Epoch 50/50\n",
            "38/38 [==============================] - 0s 866us/step - loss: 0.6872 - accuracy: 0.5428\n",
            "Accuracy on training---\n",
            "0.5427852348993288\n",
            "\n",
            "Accuracy on test---\n",
            "0.5226130653266332\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yREjBUmILmoA"
      },
      "source": [
        "The Z-score of exercisehours values and eye color as a one-hot:\n",
        "\n",
        "The accuracy of this prediction for training set is 0.5528523489932886 and the accuracy of this prediction for test set is 0.550251256281407."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYVuaPWgrePL"
      },
      "source": [
        "***\n",
        "### Question 6###\n",
        "Combine the features from question 3, 4, and 5 (year, eyecolor, exercise, height, exercise hours). For numeric features use the best normalization method from questions 4 and 5."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iAiFhlFrePM"
      },
      "source": [
        "**Question 6.a**  \n",
        "What was the NN accuracy on the test set using the single 10 node hidden layer?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuLJ6sTB1FfN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0062f3cb-7f4c-4ae3-81f3-a0547eab2ba0"
      },
      "source": [
        "#best normalization:\n",
        "# q4 -- The Z-score of height values and eye color as a one-hot\n",
        "# q5 -- The Z-score of exercise hours values and eye color as a one-hot\n",
        "\n",
        "# q3:\n",
        "df_train_bin = df_train[['year', 'eyecolor', 'exercise']]\n",
        "df_test_bin = df_test[['year', 'eyecolor', 'exercise']]\n",
        "X_train_dummy = pd.get_dummies(df_train_bin)\n",
        "X_test_dummy = pd.get_dummies(df_test_bin)\n",
        "\n",
        "# q4: z score function\n",
        "h_mean = df_train['height'].mean()\n",
        "h_std = df_train['height'].std()\n",
        "calculate_Zscore = lambda x: (x - h_mean) / h_std\n",
        "\n",
        "# apply z score to the height\n",
        "df_train_temp = df_train.copy()\n",
        "df_train_temp['height'] = df_train_temp['height'].apply(calculate_Zscore)\n",
        "df_test_temp = df_test.copy()\n",
        "df_test_temp['height'] = df_test_temp['height'].apply(calculate_Zscore)\n",
        "\n",
        "df_train_height = df_train_temp[['height']]\n",
        "df_test_height = df_test_temp[['height']]\n",
        "\n",
        "# q5: z score function\n",
        "e_mean = df_train['exercisehours'].mean()\n",
        "e_std = df_train['exercisehours'].std()\n",
        "calculate_Zscore = lambda x: (x - e_mean) / e_std\n",
        "\n",
        "# apply z score to the exercisehours\n",
        "df_train_temp = df_train.copy()\n",
        "df_train_temp['exercisehours'] = df_train_temp['exercisehours'].apply(calculate_Zscore)\n",
        "df_test_temp = df_test.copy()\n",
        "df_test_temp['exercisehours'] = df_test_temp['exercisehours'].apply(calculate_Zscore)\n",
        "\n",
        "df_train_exe = df_train_temp[['exercisehours']]\n",
        "df_test_exe = df_test_temp[['exercisehours']]\n",
        "\n",
        "# combine table\n",
        "df_train_q6 = X_train_dummy.join(df_train_height)\n",
        "df_test_q6 = X_test_dummy.join(df_test_height)\n",
        "df_train_q6 = df_train_q6.join(df_train_exe)\n",
        "df_test_q6 = df_test_q6.join(df_test_exe)\n",
        "\n",
        "#target\n",
        "y_train = df_train['gender']\n",
        "y_test = df_test['gender']\n",
        "\n",
        "#label coding for target\n",
        "le = LabelEncoder()\n",
        "le.fit(['female', 'male'])\n",
        "y_train = le.transform(y_train).reshape(-1, 1)\n",
        "y_test = le.transform(y_test).reshape(-1, 1)\n",
        "\n",
        "# keras training model\n",
        "model = Sequential()\n",
        "model.add(Dense(units=10, activation='sigmoid'))\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "model.fit(df_train_q6, y_train, epochs=50) #iter = 50\n",
        "\n",
        "print('Accuracy on training---')\n",
        "y_pred_scaled_train=model.predict(df_train_q6)\n",
        "y_pred_scaled_train=(y_pred_scaled_train>.5)*1\n",
        "print(accuracy_score(y_train, y_pred_scaled_train))\n",
        "\n",
        "print('')\n",
        "print('Accuracy on test---')\n",
        "y_pred_scaled_test=model.predict(df_test_q6)\n",
        "y_pred_scaled_test=(y_pred_scaled_test>.5)*1\n",
        "print(accuracy_score(y_test, y_pred_scaled_test))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "38/38 [==============================] - 0s 798us/step - loss: 0.7127 - accuracy: 0.3901\n",
            "Epoch 2/50\n",
            "38/38 [==============================] - 0s 979us/step - loss: 0.7058 - accuracy: 0.4891\n",
            "Epoch 3/50\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.7004 - accuracy: 0.5201\n",
            "Epoch 4/50\n",
            "38/38 [==============================] - 0s 885us/step - loss: 0.6955 - accuracy: 0.5361\n",
            "Epoch 5/50\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.6910 - accuracy: 0.5428\n",
            "Epoch 6/50\n",
            "38/38 [==============================] - 0s 837us/step - loss: 0.6867 - accuracy: 0.5445\n",
            "Epoch 7/50\n",
            "38/38 [==============================] - 0s 830us/step - loss: 0.6825 - accuracy: 0.5453\n",
            "Epoch 8/50\n",
            "38/38 [==============================] - 0s 901us/step - loss: 0.6783 - accuracy: 0.5453\n",
            "Epoch 9/50\n",
            "38/38 [==============================] - 0s 959us/step - loss: 0.6743 - accuracy: 0.5487\n",
            "Epoch 10/50\n",
            "38/38 [==============================] - 0s 864us/step - loss: 0.6702 - accuracy: 0.5495\n",
            "Epoch 11/50\n",
            "38/38 [==============================] - 0s 892us/step - loss: 0.6663 - accuracy: 0.5520\n",
            "Epoch 12/50\n",
            "38/38 [==============================] - 0s 862us/step - loss: 0.6623 - accuracy: 0.5621\n",
            "Epoch 13/50\n",
            "38/38 [==============================] - 0s 875us/step - loss: 0.6584 - accuracy: 0.5730\n",
            "Epoch 14/50\n",
            "38/38 [==============================] - 0s 878us/step - loss: 0.6545 - accuracy: 0.5805\n",
            "Epoch 15/50\n",
            "38/38 [==============================] - 0s 955us/step - loss: 0.6505 - accuracy: 0.6074\n",
            "Epoch 16/50\n",
            "38/38 [==============================] - 0s 872us/step - loss: 0.6466 - accuracy: 0.6208\n",
            "Epoch 17/50\n",
            "38/38 [==============================] - 0s 893us/step - loss: 0.6426 - accuracy: 0.6376\n",
            "Epoch 18/50\n",
            "38/38 [==============================] - 0s 897us/step - loss: 0.6387 - accuracy: 0.6384\n",
            "Epoch 19/50\n",
            "38/38 [==============================] - 0s 876us/step - loss: 0.6347 - accuracy: 0.6477\n",
            "Epoch 20/50\n",
            "38/38 [==============================] - 0s 881us/step - loss: 0.6307 - accuracy: 0.6720\n",
            "Epoch 21/50\n",
            "38/38 [==============================] - 0s 903us/step - loss: 0.6266 - accuracy: 0.6737\n",
            "Epoch 22/50\n",
            "38/38 [==============================] - 0s 779us/step - loss: 0.6226 - accuracy: 0.7030\n",
            "Epoch 23/50\n",
            "38/38 [==============================] - 0s 937us/step - loss: 0.6184 - accuracy: 0.7030\n",
            "Epoch 24/50\n",
            "38/38 [==============================] - 0s 928us/step - loss: 0.6144 - accuracy: 0.7089\n",
            "Epoch 25/50\n",
            "38/38 [==============================] - 0s 878us/step - loss: 0.6103 - accuracy: 0.7232\n",
            "Epoch 26/50\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.6061 - accuracy: 0.7248\n",
            "Epoch 27/50\n",
            "38/38 [==============================] - 0s 821us/step - loss: 0.6019 - accuracy: 0.7357\n",
            "Epoch 28/50\n",
            "38/38 [==============================] - 0s 891us/step - loss: 0.5976 - accuracy: 0.7550\n",
            "Epoch 29/50\n",
            "38/38 [==============================] - 0s 918us/step - loss: 0.5934 - accuracy: 0.7542\n",
            "Epoch 30/50\n",
            "38/38 [==============================] - 0s 852us/step - loss: 0.5891 - accuracy: 0.7676\n",
            "Epoch 31/50\n",
            "38/38 [==============================] - 0s 802us/step - loss: 0.5848 - accuracy: 0.7760\n",
            "Epoch 32/50\n",
            "38/38 [==============================] - 0s 978us/step - loss: 0.5805 - accuracy: 0.7852\n",
            "Epoch 33/50\n",
            "38/38 [==============================] - 0s 817us/step - loss: 0.5763 - accuracy: 0.7911\n",
            "Epoch 34/50\n",
            "38/38 [==============================] - 0s 921us/step - loss: 0.5719 - accuracy: 0.7953\n",
            "Epoch 35/50\n",
            "38/38 [==============================] - 0s 824us/step - loss: 0.5676 - accuracy: 0.7970\n",
            "Epoch 36/50\n",
            "38/38 [==============================] - 0s 835us/step - loss: 0.5634 - accuracy: 0.8037\n",
            "Epoch 37/50\n",
            "38/38 [==============================] - 0s 915us/step - loss: 0.5591 - accuracy: 0.8037\n",
            "Epoch 38/50\n",
            "38/38 [==============================] - 0s 902us/step - loss: 0.5548 - accuracy: 0.8121\n",
            "Epoch 39/50\n",
            "38/38 [==============================] - 0s 834us/step - loss: 0.5506 - accuracy: 0.8138\n",
            "Epoch 40/50\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.5464 - accuracy: 0.8146\n",
            "Epoch 41/50\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.5423 - accuracy: 0.8121\n",
            "Epoch 42/50\n",
            "38/38 [==============================] - 0s 848us/step - loss: 0.5381 - accuracy: 0.8163\n",
            "Epoch 43/50\n",
            "38/38 [==============================] - 0s 953us/step - loss: 0.5339 - accuracy: 0.8154\n",
            "Epoch 44/50\n",
            "38/38 [==============================] - 0s 891us/step - loss: 0.5298 - accuracy: 0.8171\n",
            "Epoch 45/50\n",
            "38/38 [==============================] - 0s 856us/step - loss: 0.5259 - accuracy: 0.8205\n",
            "Epoch 46/50\n",
            "38/38 [==============================] - 0s 859us/step - loss: 0.5219 - accuracy: 0.8205\n",
            "Epoch 47/50\n",
            "38/38 [==============================] - 0s 901us/step - loss: 0.5180 - accuracy: 0.8205\n",
            "Epoch 48/50\n",
            "38/38 [==============================] - 0s 994us/step - loss: 0.5141 - accuracy: 0.8238\n",
            "Epoch 49/50\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.5104 - accuracy: 0.8255\n",
            "Epoch 50/50\n",
            "38/38 [==============================] - 0s 844us/step - loss: 0.5067 - accuracy: 0.8255\n",
            "Accuracy on training---\n",
            "0.8238255033557047\n",
            "\n",
            "Accuracy on test---\n",
            "0.821608040201005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1foS74O01FfP"
      },
      "source": [
        "###ANSWER: \n",
        "The accuracy of this prediction for training set is 0.8238255033557047 and the accuracy of this prediction for test set is 0.821608040201005."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jusc-kofrePP"
      },
      "source": [
        "***\n",
        "### Question 7- Bonus (10%)###\n",
        "Can you improve your test set prediction accuracy by 5% or more?  \n",
        "\n",
        "See how close to that milestone of improvement you can get by modifying the tuning parameters of  Neural Networks (the number of hidden layers, number of hidden nodes in each layer, the learning rate aka mu). A great guide to tuning parameters is explained in this guide: http://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf. \n",
        "\n",
        "While the guide is specific to SVM and in particular the C and gamma parameters of the RBF kernel, the method applies to generally to any ML technique with tuning parameters.\n",
        "\n",
        "Please also write a paragraph in a markdown cell below with an explanation of your approach and evaluation metrics.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvpoUdeq1GsX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "057722fc-4f37-4ebe-acd9-3bddd85a976d"
      },
      "source": [
        "from keras.layers import Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.constraints import maxnorm\n",
        "\n",
        "#best normalization:\n",
        "# q4 -- The Z-score of height values and eye color as a one-hot\n",
        "# q5 -- The Z-score of exercise hours values and eye color as a one-hot\n",
        "\n",
        "# q3:\n",
        "df_train_bin = df_train[['year', 'eyecolor', 'exercise']]\n",
        "df_test_bin = df_test[['year', 'eyecolor', 'exercise']]\n",
        "X_train_dummy = pd.get_dummies(df_train_bin)\n",
        "X_test_dummy = pd.get_dummies(df_test_bin)\n",
        "\n",
        "# q4: z score function\n",
        "h_mean = df_train['height'].mean()\n",
        "h_std = df_train['height'].std()\n",
        "calculate_Zscore = lambda x: (x - h_mean) / h_std\n",
        "\n",
        "# apply z score to the height\n",
        "df_train_temp = df_train.copy()\n",
        "df_train_temp['height'] = df_train_temp['height'].apply(calculate_Zscore)\n",
        "df_test_temp = df_test.copy()\n",
        "df_test_temp['height'] = df_test_temp['height'].apply(calculate_Zscore)\n",
        "\n",
        "df_train_height = df_train_temp[['height']]\n",
        "df_test_height = df_test_temp[['height']]\n",
        "\n",
        "# q5: z score function\n",
        "e_mean = df_train['exercisehours'].mean()\n",
        "e_std = df_train['exercisehours'].std()\n",
        "calculate_Zscore = lambda x: (x - e_mean) / e_std\n",
        "\n",
        "# apply z score to the exercisehours\n",
        "df_train_temp = df_train.copy()\n",
        "df_train_temp['exercisehours'] = df_train_temp['exercisehours'].apply(calculate_Zscore)\n",
        "df_test_temp = df_test.copy()\n",
        "df_test_temp['exercisehours'] = df_test_temp['exercisehours'].apply(calculate_Zscore)\n",
        "\n",
        "df_train_exe = df_train_temp[['exercisehours']]\n",
        "df_test_exe = df_test_temp[['exercisehours']]\n",
        "\n",
        "# combine table\n",
        "df_train_q6 = X_train_dummy.join(df_train_height)\n",
        "df_test_q6 = X_test_dummy.join(df_test_height)\n",
        "df_train_q6 = df_train_q6.join(df_train_exe)\n",
        "df_test_q6 = df_test_q6.join(df_test_exe)\n",
        "\n",
        "#target\n",
        "y_train = df_train['gender']\n",
        "y_test = df_test['gender']\n",
        "\n",
        "#label coding for target\n",
        "le = LabelEncoder()\n",
        "le.fit(['female', 'male'])\n",
        "y_train = le.transform(y_train).reshape(-1, 1)\n",
        "y_test = le.transform(y_test).reshape(-1, 1)\n",
        "\n",
        "#keras training model\n",
        "model = Sequential()\n",
        "# model.add(Dropout(0.2, input_shape=(14,)))\n",
        "model.add(Dense(units=200, activation='sigmoid'))\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy']) #sgd, adam\n",
        "model.fit(df_train_q6, y_train, epochs=300) #iter = 300 batch_size=512,\n",
        "\n",
        "print('Accuracy on training---')\n",
        "y_pred_scaled_train=model.predict(df_train_q6)\n",
        "y_pred_scaled_train=(y_pred_scaled_train>.5)*1\n",
        "print(accuracy_score(y_train, y_pred_scaled_train))\n",
        "\n",
        "print('')\n",
        "print('Accuracy on test---')\n",
        "y_pred_scaled_test=model.predict(df_test_q6)\n",
        "y_pred_scaled_test=(y_pred_scaled_test>.5)*1\n",
        "print(accuracy_score(y_test, y_pred_scaled_test))"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "38/38 [==============================] - 0s 906us/step - loss: 0.6943 - accuracy: 0.5394\n",
            "Epoch 2/300\n",
            "38/38 [==============================] - 0s 877us/step - loss: 0.6834 - accuracy: 0.5529\n",
            "Epoch 3/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.6729 - accuracy: 0.6040\n",
            "Epoch 4/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.6646 - accuracy: 0.5872\n",
            "Epoch 5/300\n",
            "38/38 [==============================] - 0s 852us/step - loss: 0.6549 - accuracy: 0.6300\n",
            "Epoch 6/300\n",
            "38/38 [==============================] - 0s 984us/step - loss: 0.6461 - accuracy: 0.6300\n",
            "Epoch 7/300\n",
            "38/38 [==============================] - 0s 922us/step - loss: 0.6374 - accuracy: 0.7206\n",
            "Epoch 8/300\n",
            "38/38 [==============================] - 0s 908us/step - loss: 0.6285 - accuracy: 0.7206\n",
            "Epoch 9/300\n",
            "38/38 [==============================] - 0s 926us/step - loss: 0.6209 - accuracy: 0.7819\n",
            "Epoch 10/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.6130 - accuracy: 0.7592\n",
            "Epoch 11/300\n",
            "38/38 [==============================] - 0s 922us/step - loss: 0.6045 - accuracy: 0.7626\n",
            "Epoch 12/300\n",
            "38/38 [==============================] - 0s 886us/step - loss: 0.5968 - accuracy: 0.7936\n",
            "Epoch 13/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.5894 - accuracy: 0.8070\n",
            "Epoch 14/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.5824 - accuracy: 0.7928\n",
            "Epoch 15/300\n",
            "38/38 [==============================] - 0s 965us/step - loss: 0.5754 - accuracy: 0.8079\n",
            "Epoch 16/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.5686 - accuracy: 0.8247\n",
            "Epoch 17/300\n",
            "38/38 [==============================] - 0s 896us/step - loss: 0.5611 - accuracy: 0.8180\n",
            "Epoch 18/300\n",
            "38/38 [==============================] - 0s 961us/step - loss: 0.5553 - accuracy: 0.8171\n",
            "Epoch 19/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.5484 - accuracy: 0.8255\n",
            "Epoch 20/300\n",
            "38/38 [==============================] - 0s 899us/step - loss: 0.5422 - accuracy: 0.8230\n",
            "Epoch 21/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.5353 - accuracy: 0.8322\n",
            "Epoch 22/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.5298 - accuracy: 0.8347\n",
            "Epoch 23/300\n",
            "38/38 [==============================] - 0s 879us/step - loss: 0.5246 - accuracy: 0.8255\n",
            "Epoch 24/300\n",
            "38/38 [==============================] - 0s 880us/step - loss: 0.5189 - accuracy: 0.8322\n",
            "Epoch 25/300\n",
            "38/38 [==============================] - 0s 915us/step - loss: 0.5130 - accuracy: 0.8423\n",
            "Epoch 26/300\n",
            "38/38 [==============================] - 0s 962us/step - loss: 0.5085 - accuracy: 0.8347\n",
            "Epoch 27/300\n",
            "38/38 [==============================] - 0s 929us/step - loss: 0.5036 - accuracy: 0.8356\n",
            "Epoch 28/300\n",
            "38/38 [==============================] - 0s 993us/step - loss: 0.4970 - accuracy: 0.8305\n",
            "Epoch 29/300\n",
            "38/38 [==============================] - 0s 823us/step - loss: 0.4930 - accuracy: 0.8322\n",
            "Epoch 30/300\n",
            "38/38 [==============================] - 0s 857us/step - loss: 0.4883 - accuracy: 0.8230\n",
            "Epoch 31/300\n",
            "38/38 [==============================] - 0s 890us/step - loss: 0.4847 - accuracy: 0.8372\n",
            "Epoch 32/300\n",
            "38/38 [==============================] - 0s 864us/step - loss: 0.4801 - accuracy: 0.8305\n",
            "Epoch 33/300\n",
            "38/38 [==============================] - 0s 995us/step - loss: 0.4746 - accuracy: 0.8398\n",
            "Epoch 34/300\n",
            "38/38 [==============================] - 0s 857us/step - loss: 0.4717 - accuracy: 0.8406\n",
            "Epoch 35/300\n",
            "38/38 [==============================] - 0s 898us/step - loss: 0.4685 - accuracy: 0.8305\n",
            "Epoch 36/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.4641 - accuracy: 0.8280\n",
            "Epoch 37/300\n",
            "38/38 [==============================] - 0s 933us/step - loss: 0.4603 - accuracy: 0.8372\n",
            "Epoch 38/300\n",
            "38/38 [==============================] - 0s 919us/step - loss: 0.4573 - accuracy: 0.8322\n",
            "Epoch 39/300\n",
            "38/38 [==============================] - 0s 936us/step - loss: 0.4535 - accuracy: 0.8372\n",
            "Epoch 40/300\n",
            "38/38 [==============================] - 0s 852us/step - loss: 0.4506 - accuracy: 0.8389\n",
            "Epoch 41/300\n",
            "38/38 [==============================] - 0s 905us/step - loss: 0.4474 - accuracy: 0.8398\n",
            "Epoch 42/300\n",
            "38/38 [==============================] - 0s 943us/step - loss: 0.4452 - accuracy: 0.8372\n",
            "Epoch 43/300\n",
            "38/38 [==============================] - 0s 859us/step - loss: 0.4419 - accuracy: 0.8414\n",
            "Epoch 44/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.4389 - accuracy: 0.8381\n",
            "Epoch 45/300\n",
            "38/38 [==============================] - 0s 967us/step - loss: 0.4367 - accuracy: 0.8431\n",
            "Epoch 46/300\n",
            "38/38 [==============================] - 0s 899us/step - loss: 0.4340 - accuracy: 0.8431\n",
            "Epoch 47/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.4316 - accuracy: 0.8372\n",
            "Epoch 48/300\n",
            "38/38 [==============================] - 0s 891us/step - loss: 0.4298 - accuracy: 0.8440\n",
            "Epoch 49/300\n",
            "38/38 [==============================] - 0s 869us/step - loss: 0.4277 - accuracy: 0.8356\n",
            "Epoch 50/300\n",
            "38/38 [==============================] - 0s 952us/step - loss: 0.4257 - accuracy: 0.8406\n",
            "Epoch 51/300\n",
            "38/38 [==============================] - 0s 957us/step - loss: 0.4235 - accuracy: 0.8423\n",
            "Epoch 52/300\n",
            "38/38 [==============================] - 0s 980us/step - loss: 0.4211 - accuracy: 0.8448\n",
            "Epoch 53/300\n",
            "38/38 [==============================] - 0s 924us/step - loss: 0.4194 - accuracy: 0.8423\n",
            "Epoch 54/300\n",
            "38/38 [==============================] - 0s 910us/step - loss: 0.4177 - accuracy: 0.8381\n",
            "Epoch 55/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.4166 - accuracy: 0.8423\n",
            "Epoch 56/300\n",
            "38/38 [==============================] - 0s 928us/step - loss: 0.4142 - accuracy: 0.8406\n",
            "Epoch 57/300\n",
            "38/38 [==============================] - 0s 967us/step - loss: 0.4132 - accuracy: 0.8507\n",
            "Epoch 58/300\n",
            "38/38 [==============================] - 0s 923us/step - loss: 0.4119 - accuracy: 0.8372\n",
            "Epoch 59/300\n",
            "38/38 [==============================] - 0s 938us/step - loss: 0.4103 - accuracy: 0.8406\n",
            "Epoch 60/300\n",
            "38/38 [==============================] - 0s 945us/step - loss: 0.4087 - accuracy: 0.8473\n",
            "Epoch 61/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.4074 - accuracy: 0.8339\n",
            "Epoch 62/300\n",
            "38/38 [==============================] - 0s 945us/step - loss: 0.4070 - accuracy: 0.8473\n",
            "Epoch 63/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.4050 - accuracy: 0.8389\n",
            "Epoch 64/300\n",
            "38/38 [==============================] - 0s 935us/step - loss: 0.4055 - accuracy: 0.8482\n",
            "Epoch 65/300\n",
            "38/38 [==============================] - 0s 899us/step - loss: 0.4035 - accuracy: 0.8431\n",
            "Epoch 66/300\n",
            "38/38 [==============================] - 0s 889us/step - loss: 0.4024 - accuracy: 0.8440\n",
            "Epoch 67/300\n",
            "38/38 [==============================] - 0s 991us/step - loss: 0.4014 - accuracy: 0.8389\n",
            "Epoch 68/300\n",
            "38/38 [==============================] - 0s 927us/step - loss: 0.4000 - accuracy: 0.8482\n",
            "Epoch 69/300\n",
            "38/38 [==============================] - 0s 927us/step - loss: 0.3996 - accuracy: 0.8414\n",
            "Epoch 70/300\n",
            "38/38 [==============================] - 0s 995us/step - loss: 0.3990 - accuracy: 0.8423\n",
            "Epoch 71/300\n",
            "38/38 [==============================] - 0s 911us/step - loss: 0.3977 - accuracy: 0.8456\n",
            "Epoch 72/300\n",
            "38/38 [==============================] - 0s 935us/step - loss: 0.3973 - accuracy: 0.8423\n",
            "Epoch 73/300\n",
            "38/38 [==============================] - 0s 995us/step - loss: 0.3962 - accuracy: 0.8490\n",
            "Epoch 74/300\n",
            "38/38 [==============================] - 0s 921us/step - loss: 0.3956 - accuracy: 0.8414\n",
            "Epoch 75/300\n",
            "38/38 [==============================] - 0s 927us/step - loss: 0.3956 - accuracy: 0.8440\n",
            "Epoch 76/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3954 - accuracy: 0.8431\n",
            "Epoch 77/300\n",
            "38/38 [==============================] - 0s 866us/step - loss: 0.3936 - accuracy: 0.8440\n",
            "Epoch 78/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3934 - accuracy: 0.8456\n",
            "Epoch 79/300\n",
            "38/38 [==============================] - 0s 970us/step - loss: 0.3928 - accuracy: 0.8482\n",
            "Epoch 80/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3924 - accuracy: 0.8423\n",
            "Epoch 81/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3917 - accuracy: 0.8498\n",
            "Epoch 82/300\n",
            "38/38 [==============================] - 0s 880us/step - loss: 0.3912 - accuracy: 0.8440\n",
            "Epoch 83/300\n",
            "38/38 [==============================] - 0s 957us/step - loss: 0.3901 - accuracy: 0.8540\n",
            "Epoch 84/300\n",
            "38/38 [==============================] - 0s 901us/step - loss: 0.3910 - accuracy: 0.8406\n",
            "Epoch 85/300\n",
            "38/38 [==============================] - 0s 869us/step - loss: 0.3898 - accuracy: 0.8465\n",
            "Epoch 86/300\n",
            "38/38 [==============================] - 0s 890us/step - loss: 0.3892 - accuracy: 0.8448\n",
            "Epoch 87/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3892 - accuracy: 0.8532\n",
            "Epoch 88/300\n",
            "38/38 [==============================] - 0s 969us/step - loss: 0.3885 - accuracy: 0.8448\n",
            "Epoch 89/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3878 - accuracy: 0.8540\n",
            "Epoch 90/300\n",
            "38/38 [==============================] - 0s 878us/step - loss: 0.3878 - accuracy: 0.8523\n",
            "Epoch 91/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8456\n",
            "Epoch 92/300\n",
            "38/38 [==============================] - 0s 945us/step - loss: 0.3881 - accuracy: 0.8448\n",
            "Epoch 93/300\n",
            "38/38 [==============================] - 0s 941us/step - loss: 0.3868 - accuracy: 0.8465\n",
            "Epoch 94/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3864 - accuracy: 0.8448\n",
            "Epoch 95/300\n",
            "38/38 [==============================] - 0s 988us/step - loss: 0.3862 - accuracy: 0.8507\n",
            "Epoch 96/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3863 - accuracy: 0.8440\n",
            "Epoch 97/300\n",
            "38/38 [==============================] - 0s 897us/step - loss: 0.3855 - accuracy: 0.8456\n",
            "Epoch 98/300\n",
            "38/38 [==============================] - 0s 859us/step - loss: 0.3850 - accuracy: 0.8532\n",
            "Epoch 99/300\n",
            "38/38 [==============================] - 0s 851us/step - loss: 0.3851 - accuracy: 0.8456\n",
            "Epoch 100/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3845 - accuracy: 0.8498\n",
            "Epoch 101/300\n",
            "38/38 [==============================] - 0s 899us/step - loss: 0.3853 - accuracy: 0.8456\n",
            "Epoch 102/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3844 - accuracy: 0.8498\n",
            "Epoch 103/300\n",
            "38/38 [==============================] - 0s 935us/step - loss: 0.3841 - accuracy: 0.8482\n",
            "Epoch 104/300\n",
            "38/38 [==============================] - 0s 922us/step - loss: 0.3839 - accuracy: 0.8515\n",
            "Epoch 105/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3836 - accuracy: 0.8473\n",
            "Epoch 106/300\n",
            "38/38 [==============================] - 0s 954us/step - loss: 0.3837 - accuracy: 0.8482\n",
            "Epoch 107/300\n",
            "38/38 [==============================] - 0s 892us/step - loss: 0.3835 - accuracy: 0.8490\n",
            "Epoch 108/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3837 - accuracy: 0.8490\n",
            "Epoch 109/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3837 - accuracy: 0.8523\n",
            "Epoch 110/300\n",
            "38/38 [==============================] - 0s 927us/step - loss: 0.3835 - accuracy: 0.8490\n",
            "Epoch 111/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3830 - accuracy: 0.8515\n",
            "Epoch 112/300\n",
            "38/38 [==============================] - 0s 897us/step - loss: 0.3825 - accuracy: 0.8515\n",
            "Epoch 113/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3826 - accuracy: 0.8490\n",
            "Epoch 114/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3826 - accuracy: 0.8482\n",
            "Epoch 115/300\n",
            "38/38 [==============================] - 0s 983us/step - loss: 0.3817 - accuracy: 0.8523\n",
            "Epoch 116/300\n",
            "38/38 [==============================] - 0s 932us/step - loss: 0.3821 - accuracy: 0.8448\n",
            "Epoch 117/300\n",
            "38/38 [==============================] - 0s 900us/step - loss: 0.3819 - accuracy: 0.8507\n",
            "Epoch 118/300\n",
            "38/38 [==============================] - 0s 878us/step - loss: 0.3819 - accuracy: 0.8498\n",
            "Epoch 119/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3819 - accuracy: 0.8465\n",
            "Epoch 120/300\n",
            "38/38 [==============================] - 0s 949us/step - loss: 0.3817 - accuracy: 0.8523\n",
            "Epoch 121/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3819 - accuracy: 0.8507\n",
            "Epoch 122/300\n",
            "38/38 [==============================] - 0s 958us/step - loss: 0.3813 - accuracy: 0.8515\n",
            "Epoch 123/300\n",
            "38/38 [==============================] - 0s 876us/step - loss: 0.3814 - accuracy: 0.8498\n",
            "Epoch 124/300\n",
            "38/38 [==============================] - 0s 917us/step - loss: 0.3814 - accuracy: 0.8515\n",
            "Epoch 125/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3812 - accuracy: 0.8473\n",
            "Epoch 126/300\n",
            "38/38 [==============================] - 0s 879us/step - loss: 0.3810 - accuracy: 0.8498\n",
            "Epoch 127/300\n",
            "38/38 [==============================] - 0s 966us/step - loss: 0.3811 - accuracy: 0.8490\n",
            "Epoch 128/300\n",
            "38/38 [==============================] - 0s 884us/step - loss: 0.3815 - accuracy: 0.8490\n",
            "Epoch 129/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3805 - accuracy: 0.8473\n",
            "Epoch 130/300\n",
            "38/38 [==============================] - 0s 956us/step - loss: 0.3805 - accuracy: 0.8465\n",
            "Epoch 131/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3807 - accuracy: 0.8549\n",
            "Epoch 132/300\n",
            "38/38 [==============================] - 0s 987us/step - loss: 0.3802 - accuracy: 0.8515\n",
            "Epoch 133/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3806 - accuracy: 0.8523\n",
            "Epoch 134/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3807 - accuracy: 0.8490\n",
            "Epoch 135/300\n",
            "38/38 [==============================] - 0s 951us/step - loss: 0.3799 - accuracy: 0.8515\n",
            "Epoch 136/300\n",
            "38/38 [==============================] - 0s 913us/step - loss: 0.3804 - accuracy: 0.8473\n",
            "Epoch 137/300\n",
            "38/38 [==============================] - 0s 935us/step - loss: 0.3801 - accuracy: 0.8473\n",
            "Epoch 138/300\n",
            "38/38 [==============================] - 0s 909us/step - loss: 0.3800 - accuracy: 0.8532\n",
            "Epoch 139/300\n",
            "38/38 [==============================] - 0s 955us/step - loss: 0.3801 - accuracy: 0.8523\n",
            "Epoch 140/300\n",
            "38/38 [==============================] - 0s 915us/step - loss: 0.3802 - accuracy: 0.8507\n",
            "Epoch 141/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3800 - accuracy: 0.8490\n",
            "Epoch 142/300\n",
            "38/38 [==============================] - 0s 884us/step - loss: 0.3804 - accuracy: 0.8498\n",
            "Epoch 143/300\n",
            "38/38 [==============================] - 0s 919us/step - loss: 0.3802 - accuracy: 0.8507\n",
            "Epoch 144/300\n",
            "38/38 [==============================] - 0s 908us/step - loss: 0.3799 - accuracy: 0.8515\n",
            "Epoch 145/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3795 - accuracy: 0.8473\n",
            "Epoch 146/300\n",
            "38/38 [==============================] - 0s 883us/step - loss: 0.3794 - accuracy: 0.8498\n",
            "Epoch 147/300\n",
            "38/38 [==============================] - 0s 984us/step - loss: 0.3799 - accuracy: 0.8473\n",
            "Epoch 148/300\n",
            "38/38 [==============================] - 0s 941us/step - loss: 0.3793 - accuracy: 0.8515\n",
            "Epoch 149/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3800 - accuracy: 0.8482\n",
            "Epoch 150/300\n",
            "38/38 [==============================] - 0s 938us/step - loss: 0.3804 - accuracy: 0.8515\n",
            "Epoch 151/300\n",
            "38/38 [==============================] - 0s 926us/step - loss: 0.3793 - accuracy: 0.8490\n",
            "Epoch 152/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3798 - accuracy: 0.8549\n",
            "Epoch 153/300\n",
            "38/38 [==============================] - 0s 950us/step - loss: 0.3798 - accuracy: 0.8507\n",
            "Epoch 154/300\n",
            "38/38 [==============================] - 0s 995us/step - loss: 0.3798 - accuracy: 0.8482\n",
            "Epoch 155/300\n",
            "38/38 [==============================] - 0s 974us/step - loss: 0.3800 - accuracy: 0.8540\n",
            "Epoch 156/300\n",
            "38/38 [==============================] - 0s 916us/step - loss: 0.3795 - accuracy: 0.8515\n",
            "Epoch 157/300\n",
            "38/38 [==============================] - 0s 902us/step - loss: 0.3797 - accuracy: 0.8540\n",
            "Epoch 158/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3796 - accuracy: 0.8515\n",
            "Epoch 159/300\n",
            "38/38 [==============================] - 0s 815us/step - loss: 0.3795 - accuracy: 0.8507\n",
            "Epoch 160/300\n",
            "38/38 [==============================] - 0s 966us/step - loss: 0.3791 - accuracy: 0.8490\n",
            "Epoch 161/300\n",
            "38/38 [==============================] - 0s 991us/step - loss: 0.3798 - accuracy: 0.8498\n",
            "Epoch 162/300\n",
            "38/38 [==============================] - 0s 866us/step - loss: 0.3793 - accuracy: 0.8482\n",
            "Epoch 163/300\n",
            "38/38 [==============================] - 0s 872us/step - loss: 0.3795 - accuracy: 0.8490\n",
            "Epoch 164/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3789 - accuracy: 0.8549\n",
            "Epoch 165/300\n",
            "38/38 [==============================] - 0s 883us/step - loss: 0.3792 - accuracy: 0.8523\n",
            "Epoch 166/300\n",
            "38/38 [==============================] - 0s 974us/step - loss: 0.3790 - accuracy: 0.8523\n",
            "Epoch 167/300\n",
            "38/38 [==============================] - 0s 956us/step - loss: 0.3792 - accuracy: 0.8532\n",
            "Epoch 168/300\n",
            "38/38 [==============================] - 0s 952us/step - loss: 0.3786 - accuracy: 0.8482\n",
            "Epoch 169/300\n",
            "38/38 [==============================] - 0s 970us/step - loss: 0.3790 - accuracy: 0.8507\n",
            "Epoch 170/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3797 - accuracy: 0.8507\n",
            "Epoch 171/300\n",
            "38/38 [==============================] - 0s 960us/step - loss: 0.3790 - accuracy: 0.8523\n",
            "Epoch 172/300\n",
            "38/38 [==============================] - 0s 944us/step - loss: 0.3786 - accuracy: 0.8532\n",
            "Epoch 173/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3788 - accuracy: 0.8523\n",
            "Epoch 174/300\n",
            "38/38 [==============================] - 0s 971us/step - loss: 0.3789 - accuracy: 0.8498\n",
            "Epoch 175/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3795 - accuracy: 0.8498\n",
            "Epoch 176/300\n",
            "38/38 [==============================] - 0s 955us/step - loss: 0.3791 - accuracy: 0.8523\n",
            "Epoch 177/300\n",
            "38/38 [==============================] - 0s 889us/step - loss: 0.3790 - accuracy: 0.8465\n",
            "Epoch 178/300\n",
            "38/38 [==============================] - 0s 915us/step - loss: 0.3794 - accuracy: 0.8498\n",
            "Epoch 179/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3792 - accuracy: 0.8507\n",
            "Epoch 180/300\n",
            "38/38 [==============================] - 0s 937us/step - loss: 0.3789 - accuracy: 0.8507\n",
            "Epoch 181/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3787 - accuracy: 0.8523\n",
            "Epoch 182/300\n",
            "38/38 [==============================] - 0s 900us/step - loss: 0.3787 - accuracy: 0.8482\n",
            "Epoch 183/300\n",
            "38/38 [==============================] - 0s 881us/step - loss: 0.3790 - accuracy: 0.8498\n",
            "Epoch 184/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3783 - accuracy: 0.8523\n",
            "Epoch 185/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3790 - accuracy: 0.8490\n",
            "Epoch 186/300\n",
            "38/38 [==============================] - 0s 941us/step - loss: 0.3788 - accuracy: 0.8490\n",
            "Epoch 187/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3787 - accuracy: 0.8523\n",
            "Epoch 188/300\n",
            "38/38 [==============================] - 0s 969us/step - loss: 0.3790 - accuracy: 0.8498\n",
            "Epoch 189/300\n",
            "38/38 [==============================] - 0s 935us/step - loss: 0.3790 - accuracy: 0.8523\n",
            "Epoch 190/300\n",
            "38/38 [==============================] - 0s 887us/step - loss: 0.3788 - accuracy: 0.8490\n",
            "Epoch 191/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3787 - accuracy: 0.8523\n",
            "Epoch 192/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3788 - accuracy: 0.8523\n",
            "Epoch 193/300\n",
            "38/38 [==============================] - 0s 967us/step - loss: 0.3789 - accuracy: 0.8515\n",
            "Epoch 194/300\n",
            "38/38 [==============================] - 0s 932us/step - loss: 0.3792 - accuracy: 0.8515\n",
            "Epoch 195/300\n",
            "38/38 [==============================] - 0s 979us/step - loss: 0.3790 - accuracy: 0.8482\n",
            "Epoch 196/300\n",
            "38/38 [==============================] - 0s 877us/step - loss: 0.3788 - accuracy: 0.8523\n",
            "Epoch 197/300\n",
            "38/38 [==============================] - 0s 981us/step - loss: 0.3781 - accuracy: 0.8498\n",
            "Epoch 198/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3791 - accuracy: 0.8532\n",
            "Epoch 199/300\n",
            "38/38 [==============================] - 0s 890us/step - loss: 0.3787 - accuracy: 0.8532\n",
            "Epoch 200/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3789 - accuracy: 0.8507\n",
            "Epoch 201/300\n",
            "38/38 [==============================] - 0s 898us/step - loss: 0.3783 - accuracy: 0.8490\n",
            "Epoch 202/300\n",
            "38/38 [==============================] - 0s 910us/step - loss: 0.3792 - accuracy: 0.8507\n",
            "Epoch 203/300\n",
            "38/38 [==============================] - 0s 968us/step - loss: 0.3791 - accuracy: 0.8532\n",
            "Epoch 204/300\n",
            "38/38 [==============================] - 0s 961us/step - loss: 0.3787 - accuracy: 0.8507\n",
            "Epoch 205/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3794 - accuracy: 0.8523\n",
            "Epoch 206/300\n",
            "38/38 [==============================] - 0s 834us/step - loss: 0.3786 - accuracy: 0.8523\n",
            "Epoch 207/300\n",
            "38/38 [==============================] - 0s 879us/step - loss: 0.3787 - accuracy: 0.8498\n",
            "Epoch 208/300\n",
            "38/38 [==============================] - 0s 939us/step - loss: 0.3788 - accuracy: 0.8507\n",
            "Epoch 209/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3790 - accuracy: 0.8490\n",
            "Epoch 210/300\n",
            "38/38 [==============================] - 0s 905us/step - loss: 0.3787 - accuracy: 0.8515\n",
            "Epoch 211/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3786 - accuracy: 0.8523\n",
            "Epoch 212/300\n",
            "38/38 [==============================] - 0s 947us/step - loss: 0.3785 - accuracy: 0.8532\n",
            "Epoch 213/300\n",
            "38/38 [==============================] - 0s 954us/step - loss: 0.3782 - accuracy: 0.8532\n",
            "Epoch 214/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3784 - accuracy: 0.8523\n",
            "Epoch 215/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3785 - accuracy: 0.8523\n",
            "Epoch 216/300\n",
            "38/38 [==============================] - 0s 879us/step - loss: 0.3786 - accuracy: 0.8465\n",
            "Epoch 217/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3787 - accuracy: 0.8490\n",
            "Epoch 218/300\n",
            "38/38 [==============================] - 0s 946us/step - loss: 0.3786 - accuracy: 0.8515\n",
            "Epoch 219/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3783 - accuracy: 0.8523\n",
            "Epoch 220/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3783 - accuracy: 0.8482\n",
            "Epoch 221/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3785 - accuracy: 0.8523\n",
            "Epoch 222/300\n",
            "38/38 [==============================] - 0s 882us/step - loss: 0.3787 - accuracy: 0.8498\n",
            "Epoch 223/300\n",
            "38/38 [==============================] - 0s 907us/step - loss: 0.3781 - accuracy: 0.8532\n",
            "Epoch 224/300\n",
            "38/38 [==============================] - 0s 985us/step - loss: 0.3781 - accuracy: 0.8490\n",
            "Epoch 225/300\n",
            "38/38 [==============================] - 0s 927us/step - loss: 0.3791 - accuracy: 0.8498\n",
            "Epoch 226/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3784 - accuracy: 0.8515\n",
            "Epoch 227/300\n",
            "38/38 [==============================] - 0s 893us/step - loss: 0.3787 - accuracy: 0.8532\n",
            "Epoch 228/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3782 - accuracy: 0.8515\n",
            "Epoch 229/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3786 - accuracy: 0.8532\n",
            "Epoch 230/300\n",
            "38/38 [==============================] - 0s 943us/step - loss: 0.3785 - accuracy: 0.8532\n",
            "Epoch 231/300\n",
            "38/38 [==============================] - 0s 990us/step - loss: 0.3787 - accuracy: 0.8523\n",
            "Epoch 232/300\n",
            "38/38 [==============================] - 0s 912us/step - loss: 0.3782 - accuracy: 0.8507\n",
            "Epoch 233/300\n",
            "38/38 [==============================] - 0s 966us/step - loss: 0.3778 - accuracy: 0.8532\n",
            "Epoch 234/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3784 - accuracy: 0.8507\n",
            "Epoch 235/300\n",
            "38/38 [==============================] - 0s 981us/step - loss: 0.3786 - accuracy: 0.8515\n",
            "Epoch 236/300\n",
            "38/38 [==============================] - 0s 932us/step - loss: 0.3779 - accuracy: 0.8507\n",
            "Epoch 237/300\n",
            "38/38 [==============================] - 0s 916us/step - loss: 0.3788 - accuracy: 0.8482\n",
            "Epoch 238/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3784 - accuracy: 0.8498\n",
            "Epoch 239/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3782 - accuracy: 0.8523\n",
            "Epoch 240/300\n",
            "38/38 [==============================] - 0s 919us/step - loss: 0.3789 - accuracy: 0.8498\n",
            "Epoch 241/300\n",
            "38/38 [==============================] - 0s 938us/step - loss: 0.3783 - accuracy: 0.8515\n",
            "Epoch 242/300\n",
            "38/38 [==============================] - 0s 918us/step - loss: 0.3786 - accuracy: 0.8490\n",
            "Epoch 243/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3783 - accuracy: 0.8532\n",
            "Epoch 244/300\n",
            "38/38 [==============================] - 0s 903us/step - loss: 0.3781 - accuracy: 0.8515\n",
            "Epoch 245/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3783 - accuracy: 0.8515\n",
            "Epoch 246/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3785 - accuracy: 0.8498\n",
            "Epoch 247/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3786 - accuracy: 0.8523\n",
            "Epoch 248/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3780 - accuracy: 0.8523\n",
            "Epoch 249/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3785 - accuracy: 0.8540\n",
            "Epoch 250/300\n",
            "38/38 [==============================] - 0s 949us/step - loss: 0.3785 - accuracy: 0.8540\n",
            "Epoch 251/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3776 - accuracy: 0.8507\n",
            "Epoch 252/300\n",
            "38/38 [==============================] - 0s 924us/step - loss: 0.3784 - accuracy: 0.8515\n",
            "Epoch 253/300\n",
            "38/38 [==============================] - 0s 913us/step - loss: 0.3784 - accuracy: 0.8515\n",
            "Epoch 254/300\n",
            "38/38 [==============================] - 0s 867us/step - loss: 0.3787 - accuracy: 0.8515\n",
            "Epoch 255/300\n",
            "38/38 [==============================] - 0s 945us/step - loss: 0.3775 - accuracy: 0.8498\n",
            "Epoch 256/300\n",
            "38/38 [==============================] - 0s 909us/step - loss: 0.3781 - accuracy: 0.8515\n",
            "Epoch 257/300\n",
            "38/38 [==============================] - 0s 916us/step - loss: 0.3785 - accuracy: 0.8482\n",
            "Epoch 258/300\n",
            "38/38 [==============================] - 0s 919us/step - loss: 0.3784 - accuracy: 0.8515\n",
            "Epoch 259/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3782 - accuracy: 0.8498\n",
            "Epoch 260/300\n",
            "38/38 [==============================] - 0s 928us/step - loss: 0.3786 - accuracy: 0.8532\n",
            "Epoch 261/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3784 - accuracy: 0.8490\n",
            "Epoch 262/300\n",
            "38/38 [==============================] - 0s 905us/step - loss: 0.3781 - accuracy: 0.8540\n",
            "Epoch 263/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3783 - accuracy: 0.8507\n",
            "Epoch 264/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3784 - accuracy: 0.8532\n",
            "Epoch 265/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3783 - accuracy: 0.8507\n",
            "Epoch 266/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3784 - accuracy: 0.8507\n",
            "Epoch 267/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3784 - accuracy: 0.8532\n",
            "Epoch 268/300\n",
            "38/38 [==============================] - 0s 956us/step - loss: 0.3783 - accuracy: 0.8482\n",
            "Epoch 269/300\n",
            "38/38 [==============================] - 0s 965us/step - loss: 0.3789 - accuracy: 0.8498\n",
            "Epoch 270/300\n",
            "38/38 [==============================] - 0s 936us/step - loss: 0.3782 - accuracy: 0.8515\n",
            "Epoch 271/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3779 - accuracy: 0.8523\n",
            "Epoch 272/300\n",
            "38/38 [==============================] - 0s 955us/step - loss: 0.3783 - accuracy: 0.8515\n",
            "Epoch 273/300\n",
            "38/38 [==============================] - 0s 930us/step - loss: 0.3780 - accuracy: 0.8498\n",
            "Epoch 274/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3783 - accuracy: 0.8523\n",
            "Epoch 275/300\n",
            "38/38 [==============================] - 0s 970us/step - loss: 0.3778 - accuracy: 0.8498\n",
            "Epoch 276/300\n",
            "38/38 [==============================] - 0s 933us/step - loss: 0.3782 - accuracy: 0.8507\n",
            "Epoch 277/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3783 - accuracy: 0.8515\n",
            "Epoch 278/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3785 - accuracy: 0.8507\n",
            "Epoch 279/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3783 - accuracy: 0.8523\n",
            "Epoch 280/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3780 - accuracy: 0.8498\n",
            "Epoch 281/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3781 - accuracy: 0.8507\n",
            "Epoch 282/300\n",
            "38/38 [==============================] - 0s 952us/step - loss: 0.3781 - accuracy: 0.8523\n",
            "Epoch 283/300\n",
            "38/38 [==============================] - 0s 923us/step - loss: 0.3781 - accuracy: 0.8490\n",
            "Epoch 284/300\n",
            "38/38 [==============================] - 0s 955us/step - loss: 0.3787 - accuracy: 0.8490\n",
            "Epoch 285/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3785 - accuracy: 0.8490\n",
            "Epoch 286/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3785 - accuracy: 0.8473\n",
            "Epoch 287/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3784 - accuracy: 0.8523\n",
            "Epoch 288/300\n",
            "38/38 [==============================] - 0s 927us/step - loss: 0.3783 - accuracy: 0.8507\n",
            "Epoch 289/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3780 - accuracy: 0.8523\n",
            "Epoch 290/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3781 - accuracy: 0.8523\n",
            "Epoch 291/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3780 - accuracy: 0.8515\n",
            "Epoch 292/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3780 - accuracy: 0.8507\n",
            "Epoch 293/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3781 - accuracy: 0.8532\n",
            "Epoch 294/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3778 - accuracy: 0.8507\n",
            "Epoch 295/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3786 - accuracy: 0.8498\n",
            "Epoch 296/300\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.3774 - accuracy: 0.8507\n",
            "Epoch 297/300\n",
            "38/38 [==============================] - 0s 970us/step - loss: 0.3777 - accuracy: 0.8515\n",
            "Epoch 298/300\n",
            "38/38 [==============================] - 0s 909us/step - loss: 0.3784 - accuracy: 0.8507\n",
            "Epoch 299/300\n",
            "38/38 [==============================] - 0s 958us/step - loss: 0.3776 - accuracy: 0.8523\n",
            "Epoch 300/300\n",
            "38/38 [==============================] - 0s 902us/step - loss: 0.3789 - accuracy: 0.8507\n",
            "Accuracy on training---\n",
            "0.8498322147651006\n",
            "\n",
            "Accuracy on test---\n",
            "0.8618090452261307\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rFY8D4Q1GsZ"
      },
      "source": [
        "###ANSWER: \n",
        "The test accuracy improved 4% from 0.821608040201005 to 0.8618090452261307. \n",
        "\n",
        "1. I set the epochs to 300, so the entire dataset will be passed forward and backward through the neural network 300 times.\n",
        "\n",
        "2. Then I also change the dense units to 200, dimensionality of the output space. It is the unit parameter itself that plays a major role in the size of the weight matrix along with the bias vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58VplKpmOzyM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}